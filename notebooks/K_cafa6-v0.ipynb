{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":116062,"databundleVersionId":14875579,"sourceType":"competition"}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Install Dependencies & External Tools","metadata":{"id":"7NbMHN8D9tXU"}},{"cell_type":"code","source":"# 1. Install Python libraries\n!pip install -q biopython obonet networkx transformers torch tqdm\n\n# 2. Install MMseqs2 (Static binary for Linux)\n# We need this for the clustering logic in data_splits.py\n!mkdir -p /content/mmseqs\n!wget -q https://mmseqs.com/latest/mmseqs-linux-avx2.tar.gz -O /content/mmseqs/mmseqs.tar.gz\n!tar xvfz /content/mmseqs/mmseqs.tar.gz -C /content/mmseqs\n!ln -sf /content/mmseqs/mmseqs/bin/mmseqs /usr/local/bin/mmseqs\n\nprint(\"Dependencies and MMseqs2 installed.\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VChBSXL3o6qz","outputId":"2c1260f2-08cb-4209-e1c6-dd4b80b6996b","trusted":true,"execution":{"iopub.status.busy":"2026-01-28T07:58:01.383681Z","iopub.execute_input":"2026-01-28T07:58:01.384250Z","iopub.status.idle":"2026-01-28T07:58:10.717284Z","shell.execute_reply.started":"2026-01-28T07:58:01.384219Z","shell.execute_reply":"2026-01-28T07:58:10.716382Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hmmseqs/\nmmseqs/userguide.pdf\nmmseqs/examples/\nmmseqs/examples/DB.fasta\nmmseqs/examples/QUERY.fasta\nmmseqs/LICENSE.md\nmmseqs/README.md\nmmseqs/matrices/\nmmseqs/matrices/PAM120.out\nmmseqs/matrices/PAM190.out\nmmseqs/matrices/PAM130.out\nmmseqs/matrices/blosum62.out\nmmseqs/matrices/blosum80.out\nmmseqs/matrices/blosum95.out\nmmseqs/matrices/PAM20.out\nmmseqs/matrices/blosum75.out\nmmseqs/matrices/blosum100.out\nmmseqs/matrices/PAM40.out\nmmseqs/matrices/PAM100.out\nmmseqs/matrices/VTML200.out\nmmseqs/matrices/blosum35.out\nmmseqs/matrices/PAM70.out\nmmseqs/matrices/PAM170.out\nmmseqs/matrices/blosum30.out\nmmseqs/matrices/VTML40.out\nmmseqs/matrices/blosum55.out\nmmseqs/matrices/PAM30.out\nmmseqs/matrices/PAM10.out\nmmseqs/matrices/blosum65.out\nmmseqs/matrices/blosum90.out\nmmseqs/matrices/PAM160.out\nmmseqs/matrices/PAM60.out\nmmseqs/matrices/PAM50.out\nmmseqs/matrices/PAM180.out\nmmseqs/matrices/VTML160.out\nmmseqs/matrices/blosum60.out\nmmseqs/matrices/blosum85.out\nmmseqs/matrices/VTML10.out\nmmseqs/matrices/nucleotide.out\nmmseqs/matrices/VTML80.out\nmmseqs/matrices/blosum40.out\nmmseqs/matrices/PAM80.out\nmmseqs/matrices/PAM110.out\nmmseqs/matrices/VTML20.out\nmmseqs/matrices/PAM90.out\nmmseqs/matrices/blosum45.out\nmmseqs/matrices/VTML120.out\nmmseqs/matrices/blosum70.out\nmmseqs/matrices/PAM150.out\nmmseqs/matrices/blosum50.out\nmmseqs/matrices/PAM140.out\nmmseqs/bin/\nmmseqs/bin/mmseqs\nmmseqs/util/\nmmseqs/util/bash-completion.sh\nDependencies and MMseqs2 installed.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Write Source Code modules","metadata":{"id":"0cs9OgmXAeCv"}},{"cell_type":"code","source":"import os\nos.makedirs('src', exist_ok=True)\n\n# Add src to python path for immediate imports if needed\nimport sys\nsys.path.append('/content/src')","metadata":{"id":"B5SwH3H0AfLI","trusted":true,"execution":{"iopub.status.busy":"2026-01-25T08:02:33.997021Z","iopub.execute_input":"2026-01-25T08:02:33.997292Z","iopub.status.idle":"2026-01-25T08:02:34.001331Z","shell.execute_reply.started":"2026-01-25T08:02:33.997260Z","shell.execute_reply":"2026-01-25T08:02:34.000737Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"%%writefile src/go_labeler.py\n\"\"\"\nGO Labeler: Handles Gene Ontology logic for protein function prediction.\n\"\"\"\nimport numpy as np\nimport obonet\nimport networkx as nx\nfrom collections import defaultdict\nfrom typing import List, Tuple, Dict, Set, Optional\n\nclass GOLabeler:\n    def __init__(self, obo_path: str, annotations: List[Tuple[str, str]]):\n        self.obo_path = obo_path\n        self.annotations = annotations\n        print(f\"Loading GO graph from {obo_path}...\")\n        self.go_graph = obonet.read_obo(obo_path)\n        print(f\"Loaded GO graph with {self.go_graph.number_of_nodes()} terms.\")\n\n        self.term_to_index: Dict[str, int] = {}\n        self.index_to_term: Dict[int, str] = {}\n        self.valid_terms: List[str] = []\n        self._term_frequencies: Dict[str, int] = {}\n\n    def _get_ancestors(self, term_id: str) -> Set[str]:\n        ancestors = set()\n        if term_id not in self.go_graph:\n            return ancestors\n        ancestors.add(term_id)\n        try:\n            ancestors.update(nx.descendants(self.go_graph, term_id))\n        except nx.NetworkXError:\n            pass\n        return ancestors\n\n    def _propagate_terms(self, terms: List[str]) -> Set[str]:\n        all_terms = set()\n        for term in terms:\n            all_terms.update(self._get_ancestors(term))\n        return all_terms\n\n    def build_label_vocabulary(self, min_frequency: int = 50) -> None:\n        print(f\"Building label vocabulary with min_frequency={min_frequency}...\")\n        protein_to_terms: Dict[str, List[str]] = defaultdict(list)\n        for protein_id, term_id in self.annotations:\n            protein_to_terms[protein_id].append(term_id)\n\n        term_counts: Dict[str, int] = defaultdict(int)\n        for protein_id, terms in protein_to_terms.items():\n            propagated_terms = self._propagate_terms(terms)\n            for term in propagated_terms:\n                term_counts[term] += 1\n\n        self._term_frequencies = dict(term_counts)\n        self.valid_terms = sorted([\n            term for term, count in term_counts.items()\n            if count >= min_frequency\n        ])\n\n        print(f\"Terms meeting min_frequency threshold: {len(self.valid_terms)}\")\n        self.term_to_index = {term: idx for idx, term in enumerate(self.valid_terms)}\n        self.index_to_term = {idx: term for idx, term in enumerate(self.valid_terms)}\n\n    def get_vector(self, protein_terms: List[str]) -> np.ndarray:\n        if not self.valid_terms:\n            raise ValueError(\"Vocabulary not built.\")\n        vector = np.zeros(len(self.valid_terms), dtype=np.float32)\n        propagated_terms = self._propagate_terms(protein_terms)\n        for term in propagated_terms:\n            if term in self.term_to_index:\n                idx = self.term_to_index[term]\n                vector[idx] = 1.0\n        return vector\n\n    def vocabulary_size(self) -> int:\n        return len(self.valid_terms)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p6IRkiHHAo-X","outputId":"f261825b-f02b-42ee-8e71-22c2910ca2d1","trusted":true,"execution":{"iopub.status.busy":"2026-01-25T08:02:34.002269Z","iopub.execute_input":"2026-01-25T08:02:34.002461Z","iopub.status.idle":"2026-01-25T08:02:34.016531Z","shell.execute_reply.started":"2026-01-25T08:02:34.002443Z","shell.execute_reply":"2026-01-25T08:02:34.015901Z"}},"outputs":[{"name":"stdout","text":"Overwriting src/go_labeler.py\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"%%writefile src/data_splits.py\n\"\"\"\nData Splitting Utilities for Protein Function Prediction.\n\"\"\"\nimport random\nfrom collections import defaultdict\nfrom typing import Dict, List, Set, Tuple, Optional\n\ndef create_splits(\n    cluster_file: str,\n    val_ratio: float = 0.2,\n    random_seed: Optional[int] = 42\n) -> Tuple[Set[str], Set[str]]:\n    if random_seed is not None:\n        random.seed(random_seed)\n\n    clusters: Dict[str, List[str]] = defaultdict(list)\n    print(f\"Reading cluster file: {cluster_file}\")\n    with open(cluster_file, 'r') as f:\n        for line in f:\n            line = line.strip()\n            if not line: continue\n            parts = line.split('\\t')\n            if len(parts) < 2: continue\n            cluster_rep, sequence_member = parts[0], parts[1]\n            clusters[cluster_rep].append(sequence_member)\n\n    cluster_reps = list(clusters.keys())\n    n_clusters = len(cluster_reps)\n    total_sequences = sum(len(members) for members in clusters.values())\n    print(f\"Found {n_clusters} clusters containing {total_sequences} sequences\")\n\n    random.shuffle(cluster_reps)\n    n_val_clusters = int(n_clusters * val_ratio)\n\n    val_cluster_reps = set(cluster_reps[:n_val_clusters])\n\n    train_protein_ids: Set[str] = set()\n    val_protein_ids: Set[str] = set()\n\n    for cluster_rep, members in clusters.items():\n        if cluster_rep in val_cluster_reps:\n            val_protein_ids.update(members)\n        else:\n            train_protein_ids.update(members)\n\n    print(f\"Split complete: Train {len(train_protein_ids)}, Val {len(val_protein_ids)}\")\n    return train_protein_ids, val_protein_ids","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bU3gwx8GA_ZD","outputId":"2ba790ba-6e29-48a3-8039-dd99b75e5a71","trusted":true,"execution":{"iopub.status.busy":"2026-01-25T08:02:34.017414Z","iopub.execute_input":"2026-01-25T08:02:34.017689Z","iopub.status.idle":"2026-01-25T08:02:34.030831Z","shell.execute_reply.started":"2026-01-25T08:02:34.017649Z","shell.execute_reply":"2026-01-25T08:02:34.030381Z"}},"outputs":[{"name":"stdout","text":"Overwriting src/data_splits.py\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"%%writefile src/dataset.py\n\"\"\"\nPyTorch Dataset for Protein Function Prediction.\n\"\"\"\nimport os\nfrom pathlib import Path\nfrom typing import Dict, List, Tuple, Optional\nimport torch\nfrom torch.utils.data import Dataset\nimport numpy as np\n\nclass ProteinGODataset(Dataset):\n    def __init__(\n        self,\n        protein_ids: List[str],\n        labeler,\n        embedding_dir: str,\n        annotations: Dict[str, List[str]],\n        check_exists: bool = True\n    ):\n        self.labeler = labeler\n        self.embedding_dir = Path(embedding_dir)\n        self.annotations = annotations\n\n        if check_exists:\n            self.protein_ids = []\n            for pid in protein_ids:\n                embedding_path = self.embedding_dir / f\"{pid}.pt\"\n                if embedding_path.exists():\n                    self.protein_ids.append(pid)\n        else:\n            self.protein_ids = list(protein_ids)\n\n        print(f\"Dataset initialized with {len(self.protein_ids)} proteins\")\n\n    def __len__(self) -> int:\n        return len(self.protein_ids)\n\n    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n        protein_id = self.protein_ids[idx]\n        embedding_path = self.embedding_dir / f\"{protein_id}.pt\"\n        embedding = torch.load(embedding_path, weights_only=True).to(torch.float32)\n\n        explicit_terms = self.annotations.get(protein_id, [])\n        label_numpy = self.labeler.get_vector(explicit_terms)\n        label = torch.from_numpy(label_numpy).to(torch.float32)\n\n        return embedding, label","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b8jBCQEGBEVF","outputId":"bb70825e-f55b-445e-8077-18380dc9c98b","trusted":true,"execution":{"iopub.status.busy":"2026-01-25T08:02:34.032579Z","iopub.execute_input":"2026-01-25T08:02:34.032840Z","iopub.status.idle":"2026-01-25T08:02:34.046321Z","shell.execute_reply.started":"2026-01-25T08:02:34.032820Z","shell.execute_reply":"2026-01-25T08:02:34.045625Z"}},"outputs":[{"name":"stdout","text":"Overwriting src/dataset.py\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"%%writefile src/model.py\n\"\"\"\nNeural Network Model and Loss Components.\n\"\"\"\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nfrom typing import Optional\n\nclass ProteinMLP(nn.Module):\n    def __init__(self, num_classes: int, input_dim: int = 1280, hidden_dim: int = 512, dropout: float = 0.3):\n        super().__init__()\n        self.input_dim = input_dim\n        self.hidden_dim = hidden_dim\n        self.num_classes = num_classes\n\n        self.hidden = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.BatchNorm1d(hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(dropout)\n        )\n        self.output = nn.Linear(hidden_dim, num_classes)\n        self._init_weights()\n\n    def _init_weights(self):\n        for module in self.modules():\n            if isinstance(module, nn.Linear):\n                nn.init.xavier_uniform_(module.weight)\n                if module.bias is not None:\n                    nn.init.zeros_(module.bias)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.hidden(x)\n        return self.output(x)\n\ndef calculate_pos_weights(train_dataset, num_workers: int = 0, batch_size: int = 256) -> torch.Tensor:\n    loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n    _, first_label = train_dataset[0]\n    num_classes = first_label.shape[0]\n\n    positive_counts = torch.zeros(num_classes, dtype=torch.float64)\n    total_samples = 0\n\n    print(\"Calculating positive class weights...\")\n    for _, labels in tqdm(loader, desc=\"Computing weights\"):\n        positive_counts += labels.sum(dim=0).to(torch.float64)\n        total_samples += labels.shape[0]\n\n    epsilon = 1e-7\n    negative_counts = total_samples - positive_counts\n    pos_weights = negative_counts / (positive_counts + epsilon)\n    pos_weights = torch.clamp(pos_weights, min=1.0, max=100.0)\n\n    return pos_weights.to(torch.float32)\n\ndef create_loss_function(pos_weights: Optional[torch.Tensor] = None, device: str = \"cuda\") -> nn.BCEWithLogitsLoss:\n    if pos_weights is not None:\n        pos_weights = pos_weights.to(device)\n        return nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n    return nn.BCEWithLogitsLoss()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uMwO_mIqBGuy","outputId":"7bc7cd0b-b60a-4511-afb5-bd9ad273213a","trusted":true,"execution":{"iopub.status.busy":"2026-01-25T08:02:34.047226Z","iopub.execute_input":"2026-01-25T08:02:34.047658Z","iopub.status.idle":"2026-01-25T08:02:34.062250Z","shell.execute_reply.started":"2026-01-25T08:02:34.047637Z","shell.execute_reply":"2026-01-25T08:02:34.061535Z"}},"outputs":[{"name":"stdout","text":"Overwriting src/model.py\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"%%writefile src/threshold_optimizer.py\n\"\"\"\nThreshold Optimization for Multi-Label Classification.\n\"\"\"\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom torch.amp import autocast\nfrom sklearn.metrics import precision_recall_curve, f1_score\nfrom tqdm import tqdm\nfrom typing import Tuple, Optional\n\ndef collect_predictions(model, data_loader, device, use_amp=True):\n    model.eval()\n    use_amp = use_amp and device == \"cuda\"\n    all_probs = []\n    all_labels = []\n\n    with torch.no_grad():\n        for embeddings, labels in tqdm(data_loader, desc=\"Collecting predictions\"):\n            embeddings = embeddings.to(device)\n            with autocast(device_type=device, enabled=use_amp):\n                logits = model(embeddings)\n            probs = torch.sigmoid(logits).cpu().numpy()\n            all_probs.append(probs)\n            all_labels.append(labels.numpy())\n\n    return np.concatenate(all_probs, axis=0), np.concatenate(all_labels, axis=0)\n\ndef optimize_thresholds(model, val_loader, device, use_amp=True) -> np.ndarray:\n    print(\"Optimizing Per-Class Thresholds\")\n    y_probs, y_true = collect_predictions(model, val_loader, device, use_amp)\n    n_classes = y_probs.shape[1]\n    optimal_thresholds = np.full(n_classes, 0.5)\n\n    for class_idx in tqdm(range(n_classes), desc=\"Optimizing\"):\n        y_true_class = y_true[:, class_idx]\n        if y_true_class.sum() == 0 or y_true_class.sum() == len(y_true_class):\n            continue\n\n        precision, recall, thresholds = precision_recall_curve(y_true_class, y_probs[:, class_idx])\n        with np.errstate(divide='ignore', invalid='ignore'):\n            f1_scores = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1])\n            f1_scores = np.nan_to_num(f1_scores, nan=0.0)\n\n        if len(f1_scores) > 0 and f1_scores.max() > 0:\n            optimal_thresholds[class_idx] = thresholds[np.argmax(f1_scores)]\n\n    return optimal_thresholds\n\ndef evaluate_with_thresholds(model, data_loader, device, thresholds, use_amp=True):\n    y_probs, y_true = collect_predictions(model, data_loader, device, use_amp)\n    y_pred = (y_probs >= thresholds).astype(np.float32)\n    micro_f1 = f1_score(y_true, y_pred, average='micro', zero_division=0)\n    macro_f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n\n    print(f\"Evaluation - Micro F1: {micro_f1:.4f}, Macro F1: {macro_f1:.4f}\")\n    return {'micro_f1': micro_f1, 'macro_f1': macro_f1}","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MX0CiJLZBJCt","outputId":"3da34396-0bf7-44d1-d3d0-eeaf677993e9","trusted":true,"execution":{"iopub.status.busy":"2026-01-25T08:02:34.063066Z","iopub.execute_input":"2026-01-25T08:02:34.063288Z","iopub.status.idle":"2026-01-25T08:02:34.078246Z","shell.execute_reply.started":"2026-01-25T08:02:34.063269Z","shell.execute_reply":"2026-01-25T08:02:34.077716Z"}},"outputs":[{"name":"stdout","text":"Overwriting src/threshold_optimizer.py\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"%%writefile src/trainer.py\nimport time\nfrom pathlib import Path\nfrom typing import Optional, Dict, Any\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom torch.amp import GradScaler, autocast\nfrom tqdm import tqdm\n\ndef train_model(\n    model: nn.Module,\n    train_loader: DataLoader,\n    val_loader: DataLoader,\n    loss_fn: nn.Module,\n    optimizer: torch.optim.Optimizer,\n    device: str,\n    epochs: int,\n    patience: int = 5,\n    checkpoint_dir: str = \"models\",\n    checkpoint_name: str = \"best_model.pt\",\n    scheduler: Optional[torch.optim.lr_scheduler._LRScheduler] = None,\n    use_amp: bool = True\n) -> Dict[str, Any]:\n    \n    Path(checkpoint_dir).mkdir(parents=True, exist_ok=True)\n    best_model_path = Path(checkpoint_dir) / checkpoint_name\n    \n    # Only use AMP if requested AND device is cuda\n    use_amp = use_amp and (device == \"cuda\")\n    scaler = GradScaler(enabled=use_amp)\n    \n    train_losses, val_losses = [], []\n    best_val_loss = float('inf')\n    best_epoch = 0\n    patience_counter = 0\n    stopped_early = False\n    \n    # Note: Model is assumed to be moved to device (or wrapped in DataParallel) by main.py\n    \n    for epoch in range(epochs):\n        model.train()\n        train_loss_sum = 0.0\n        batches = 0\n        \n        # Training Loop\n        for embeddings, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1} Train\", leave=False):\n            # If DataParallel, input is split automatically\n            embeddings, labels = embeddings.to(device), labels.to(device)\n            optimizer.zero_grad()\n            \n            with autocast(device_type=device, enabled=use_amp):\n                logits = model(embeddings)\n                loss = loss_fn(logits, labels)\n            \n            scaler.scale(loss).backward()\n            scaler.unscale_(optimizer)\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            scaler.step(optimizer)\n            scaler.update()\n            \n            train_loss_sum += loss.item()\n            batches += 1\n            \n        avg_train_loss = train_loss_sum / batches\n        train_losses.append(avg_train_loss)\n        \n        # Validation Loop\n        model.eval()\n        val_loss_sum = 0.0\n        val_batches = 0\n        with torch.no_grad():\n            for embeddings, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1} Val\", leave=False):\n                embeddings, labels = embeddings.to(device), labels.to(device)\n                with autocast(device_type=device, enabled=use_amp):\n                    logits = model(embeddings)\n                    loss = loss_fn(logits, labels)\n                val_loss_sum += loss.item()\n                val_batches += 1\n        \n        avg_val_loss = val_loss_sum / val_batches\n        val_losses.append(avg_val_loss)\n        \n        # Scheduler Step\n        if scheduler:\n            if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n                scheduler.step(avg_val_loss)\n            else:\n                scheduler.step()\n                \n        print(f\"Epoch {epoch+1} - Train: {avg_train_loss:.4f}, Val: {avg_val_loss:.4f}\")\n        \n        # Early Stopping & Checkpointing\n        if avg_val_loss < best_val_loss:\n            best_val_loss = avg_val_loss\n            best_epoch = epoch + 1\n            patience_counter = 0\n            \n            # Handle DataParallel: save the underlying module, not the wrapper\n            if isinstance(model, nn.DataParallel):\n                state_dict = model.module.state_dict()\n            else:\n                state_dict = model.state_dict()\n                \n            torch.save({\n                'model_state_dict': state_dict,\n                'val_loss': best_val_loss,\n                'config': {\n                    'input_dim': model.module.input_dim if isinstance(model, nn.DataParallel) else model.input_dim,\n                    'num_classes': model.module.num_classes if isinstance(model, nn.DataParallel) else model.num_classes\n                }\n            }, best_model_path)\n        else:\n            patience_counter += 1\n            if patience_counter >= patience:\n                print(\"Early stopping triggered.\")\n                stopped_early = True\n                break\n                \n    # Load best model for return\n    # We load into the original model architecture\n    print(\"Loading best model weights...\")\n    checkpoint = torch.load(best_model_path)\n    \n    if isinstance(model, nn.DataParallel):\n        model.module.load_state_dict(checkpoint['model_state_dict'])\n    else:\n        model.load_state_dict(checkpoint['model_state_dict'])\n    \n    return {'train_losses': train_losses, 'val_losses': val_losses, 'best_epoch': best_epoch, 'best_val_loss': best_val_loss}\n\ndef load_checkpoint(model, path, device=\"cpu\"):\n    \"\"\"\n    Load a checkpoint. Handles mismatch between DataParallel and single model.\n    \"\"\"\n    checkpoint = torch.load(path, map_location=device)\n    state_dict = checkpoint['model_state_dict']\n    \n    # If loading into a DataParallel model but checkpoint is standard\n    if isinstance(model, nn.DataParallel):\n        model.module.load_state_dict(state_dict)\n    else:\n        # If checkpoint has 'module.' prefix (from raw DP save) but model is standard\n        # (This handles cases where simple torch.save(model.state_dict()) was used on DP)\n        new_state_dict = {}\n        for k, v in state_dict.items():\n            if k.startswith('module.'):\n                new_state_dict[k[7:]] = v\n            else:\n                new_state_dict[k] = v\n        model.load_state_dict(new_state_dict)\n        \n    return model, {}","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7qdCyY0BBNYd","outputId":"ebd7d424-b656-4ce8-be84-849e9e77a7e7","trusted":true,"execution":{"iopub.status.busy":"2026-01-25T08:02:34.079007Z","iopub.execute_input":"2026-01-25T08:02:34.079238Z","iopub.status.idle":"2026-01-25T08:02:34.094882Z","shell.execute_reply.started":"2026-01-25T08:02:34.079213Z","shell.execute_reply":"2026-01-25T08:02:34.094347Z"}},"outputs":[{"name":"stdout","text":"Overwriting src/trainer.py\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"%%writefile src/extract_embeddings.py\nimport os\nimport argparse\nimport math\nfrom pathlib import Path\nimport torch\nimport torch.multiprocessing as mp\nfrom transformers import AutoTokenizer, AutoModel\nfrom Bio import SeqIO\nfrom tqdm import tqdm\n\n# Configuration\nMAX_SEQUENCE_LENGTH = 1022\n\ndef get_device(gpu_id):\n    return f\"cuda:{gpu_id}\"\n\ndef worker_process(gpu_id, all_records, output_dir, model_name):\n    \"\"\"\n    Worker function to run on a specific GPU.\n    \"\"\"\n    device = get_device(gpu_id)\n    print(f\"[GPU {gpu_id}] Initializing model {model_name}...\")\n    \n    # 1. Calculate the slice of data for this GPU\n    total_records = len(all_records)\n    n_gpus = torch.cuda.device_count()\n    chunk_size = math.ceil(total_records / n_gpus)\n    \n    start_idx = gpu_id * chunk_size\n    end_idx = min(start_idx + chunk_size, total_records)\n    \n    my_records = all_records[start_idx:end_idx]\n    \n    print(f\"[GPU {gpu_id}] Processing indices {start_idx} to {end_idx} ({len(my_records)} sequences)\")\n    \n    # 2. Load model\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    model = AutoModel.from_pretrained(model_name).to(device)\n    model.eval()\n    \n    output_path = Path(output_dir)\n    processed_count = 0\n    \n    # 3. Process assigned records\n    for record in tqdm(my_records, desc=f\"GPU {gpu_id}\", position=gpu_id):\n        out_file = output_path / f\"{record.id}.pt\"\n        \n        # Skip if already exists\n        if out_file.exists():\n            continue\n            \n        sequence = str(record.seq)\n        \n        # Truncate\n        if len(sequence) > MAX_SEQUENCE_LENGTH:\n            sequence = sequence[:MAX_SEQUENCE_LENGTH]\n            \n        try:\n            # Tokenize\n            inputs = tokenizer(\n                sequence, \n                return_tensors=\"pt\", \n                padding=False, \n                truncation=True, \n                max_length=MAX_SEQUENCE_LENGTH + 2\n            )\n            inputs = {k: v.to(device) for k, v in inputs.items()}\n            \n            # Inference\n            with torch.no_grad():\n                outputs = model(**inputs)\n            \n            # Mean pooling (exclude CLS and EOS)\n            embedding = outputs.last_hidden_state[:, 1:-1, :].mean(dim=1).squeeze(0)\n            \n            # Save to CPU\n            torch.save(embedding.cpu(), out_file)\n            processed_count += 1\n            \n        except Exception as e:\n            print(f\"[GPU {gpu_id}] Error processing {record.id}: {e}\")\n\n    print(f\"[GPU {gpu_id}] Finished. Processed {processed_count} sequences.\")\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--fasta\", required=True)\n    parser.add_argument(\"--output\", required=True)\n    parser.add_argument(\"--model\", default=\"facebook/esm2_t36_3B_UR50D\")\n    args = parser.parse_args()\n    \n    Path(args.output).mkdir(parents=True, exist_ok=True)\n    \n    print(f\"Reading FASTA file: {args.fasta}\")\n    all_records = list(SeqIO.parse(args.fasta, \"fasta\"))\n    print(f\"Total sequences: {len(all_records)}\")\n    \n    n_gpus = torch.cuda.device_count()\n    if n_gpus < 1:\n        print(\"No GPUs found! Using CPU (single process).\")\n        worker_process(0, all_records, args.output, args.model)\n        return\n\n    print(f\"Found {n_gpus} GPUs. Spawning workers...\")\n    \n    # Pass the FULL list to all workers; they will slice it themselves based on their gpu_id\n    mp.spawn(\n        worker_process,\n        args=(all_records, args.output, args.model),\n        nprocs=n_gpus,\n        join=True\n    )\n    print(\"All extraction processes completed.\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kcB4V_s4BRiO","outputId":"db619eb2-6e59-4443-bc29-c63927e3593f","trusted":true,"execution":{"iopub.status.busy":"2026-01-25T08:02:34.095723Z","iopub.execute_input":"2026-01-25T08:02:34.095991Z","iopub.status.idle":"2026-01-25T08:02:34.110921Z","shell.execute_reply.started":"2026-01-25T08:02:34.095966Z","shell.execute_reply":"2026-01-25T08:02:34.110318Z"}},"outputs":[{"name":"stdout","text":"Overwriting src/extract_embeddings.py\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"%%writefile src/main.py\nimport os\nimport sys\nimport argparse\nfrom pathlib import Path\nfrom collections import defaultdict\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\n\nfrom go_labeler import GOLabeler\nfrom data_splits import create_splits\nfrom dataset import ProteinGODataset\nfrom model import ProteinMLP, calculate_pos_weights, create_loss_function\nfrom trainer import train_model, load_checkpoint\nfrom threshold_optimizer import optimize_thresholds, evaluate_with_thresholds\n\ndef load_annotations(path):\n    ann_list, ann_dict = [], defaultdict(list)\n    with open(path, 'r') as f:\n        for line in f:\n            line = line.strip()\n            if not line: continue\n            parts = line.split('\\t')\n            if len(parts) >= 2:\n                ann_list.append((parts[0], parts[1]))\n                ann_dict[parts[0]].append(parts[1])\n    return ann_list, dict(ann_dict)\n\ndef main(args):\n    # Device Setup\n    if torch.cuda.is_available():\n        device = \"cuda\"\n        n_gpus = torch.cuda.device_count()\n        print(f\"Using {n_gpus} GPUs!\")\n    else:\n        device = \"cpu\"\n        print(\"Using CPU\")\n    \n    # 1. Load Data\n    annotations_list, annotations_dict = load_annotations(args.annotations_path)\n    labeler = GOLabeler(args.obo_path, annotations_list)\n    labeler.build_label_vocabulary(min_frequency=args.min_frequency)\n    \n    # 2. Splits\n    train_ids, val_ids = create_splits(args.cluster_path, args.val_ratio, args.seed)\n    train_ids = train_ids & set(annotations_dict.keys())\n    val_ids = val_ids & set(annotations_dict.keys())\n    \n    # 3. Datasets\n    train_dataset = ProteinGODataset(list(train_ids), labeler, args.embedding_dir, annotations_dict)\n    val_dataset = ProteinGODataset(list(val_ids), labeler, args.embedding_dir, annotations_dict)\n    \n    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers)\n    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers)\n    \n    # 4. Model Setup\n    pos_weights = calculate_pos_weights(train_dataset) if args.use_pos_weights else None\n    \n    model = ProteinMLP(\n        num_classes=labeler.vocabulary_size(), \n        input_dim=args.input_dim, \n        hidden_dim=args.hidden_dim, \n        dropout=args.dropout\n    )\n    \n    # Wrap model for Multi-GPU\n    if torch.cuda.device_count() > 1:\n        print(f\"Wrapping model in DataParallel (Batch size {args.batch_size} will be split across GPUs)\")\n        model = nn.DataParallel(model)\n    \n    model = model.to(device)\n    \n    loss_fn = create_loss_function(pos_weights, device)\n    optimizer = torch.optim.AdamW(model.parameters(), lr=args.learning_rate, weight_decay=args.weight_decay)\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n    \n    # 5. Train\n    train_model(\n        model, train_loader, val_loader, loss_fn, optimizer, device, \n        args.epochs, args.patience, args.output_dir, \"best_model.pt\", scheduler,\n        use_amp=args.use_amp # Passed from args\n    )\n    \n    # 6. Optimization\n    print(\"Loading best model for optimization...\")\n    # Load best model (Trainer handles un-wrapping, so we just reload into the object)\n    # But we need to handle if the current 'model' object is wrapped or not\n    checkpoint_path = str(Path(args.output_dir)/\"best_model.pt\")\n    model, _ = load_checkpoint(model, checkpoint_path, device)\n    \n    thresholds = optimize_thresholds(model, val_loader, device)\n    evaluate_with_thresholds(model, val_loader, device, thresholds)\n    \n    # Save artifacts\n    np.save(Path(args.output_dir)/\"thresholds.npy\", thresholds)\n    np.savez(Path(args.output_dir)/\"vocabulary.npz\", valid_terms=np.array(labeler.valid_terms))\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--obo_path\", default=\"/kaggle/input/cafa-6-protein-function-prediction/Train/go-basic.obo\")\n    parser.add_argument(\"--annotations_path\", default=\"/kaggle/input/cafa-6-protein-function-prediction/Train/train_terms.tsv\")\n    parser.add_argument(\"--cluster_path\", default=\"data/splits/train_cluster.tsv\")\n    parser.add_argument(\"--embedding_dir\", default=\"data/embeddings/train\")\n    parser.add_argument(\"--output_dir\", default=\"results/experiment_001\")\n    \n    # Updated defaults for 3B model\n    parser.add_argument(\"--input_dim\", type=int, default=1280)\n    \n    parser.add_argument(\"--hidden_dim\", type=int, default=512)\n    parser.add_argument(\"--dropout\", type=float, default=0.3)\n    parser.add_argument(\"--batch_size\", type=int, default=256)\n    parser.add_argument(\"--epochs\", type=int, default=50)\n    parser.add_argument(\"--patience\", type=int, default=5)\n    parser.add_argument(\"--learning_rate\", type=float, default=1e-4)\n    parser.add_argument(\"--weight_decay\", type=float, default=1e-5)\n    parser.add_argument(\"--min_frequency\", type=int, default=50)\n    parser.add_argument(\"--val_ratio\", type=float, default=0.2)\n    parser.add_argument(\"--use_pos_weights\", action=\"store_true\")\n    \n    # Default to FALSE for AMP if user wants strict f32, or TRUE if they just want speed\n    # Since prompt said \"no need to cast into f16\", we can default this to False to be safe\n    # or keep it True for training speed (Trainer handles it safely). \n    # I'll default to False to strictly follow the user's \"f32 works\" sentiment.\n    parser.add_argument(\"--use_amp\", action=\"store_true\", help=\"Enable Mixed Precision Training\")\n    \n    parser.add_argument(\"--num_workers\", type=int, default=4)\n    parser.add_argument(\"--seed\", type=int, default=42)\n    args = parser.parse_args()\n    main(args)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mDUJJL5rBUOp","outputId":"97b698cd-9e45-45fa-ac86-b3add3e1f36e","trusted":true,"execution":{"iopub.status.busy":"2026-01-25T08:02:34.111837Z","iopub.execute_input":"2026-01-25T08:02:34.112101Z","iopub.status.idle":"2026-01-25T08:02:34.127435Z","shell.execute_reply.started":"2026-01-25T08:02:34.112070Z","shell.execute_reply":"2026-01-25T08:02:34.126695Z"}},"outputs":[{"name":"stdout","text":"Overwriting src/main.py\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"# Data Processing - Clustering","metadata":{"id":"h-6K3LUvBbBC"}},{"cell_type":"code","source":"# Generate clusters (30% identity)\n# This creates data/splits/train_cluster.tsv\n!mmseqs easy-linclust \\\n    /kaggle/input/cafa-6-protein-function-prediction/Train/train_sequences.fasta \\\n    ./data/splits/train \\\n    tmp \\\n    --min-seq-id 0.3 \\\n    --cov-mode 1 \\\n    -c 0.8\n\n# Rename output to match what src/data_splits.py expects\n!mv data/splits/train_cluster.tsv data/splits/train_cluster.tsv.bak\n# Filter out headers if any and ensure tab separated\n!awk '{print $1\"\\t\"$2}' data/splits/train_cluster.tsv.bak > data/splits/train_cluster.tsv\n!head -n 5 data/splits/train_cluster.tsv","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oMO1vrwdBb6f","outputId":"21288406-9e54-4697-9226-8e41c5dbd866","trusted":true,"execution":{"iopub.status.busy":"2026-01-25T08:02:34.128253Z","iopub.execute_input":"2026-01-25T08:02:34.128522Z","iopub.status.idle":"2026-01-25T08:02:47.704580Z","shell.execute_reply.started":"2026-01-25T08:02:34.128503Z","shell.execute_reply":"2026-01-25T08:02:47.703911Z"}},"outputs":[{"name":"stdout","text":"easy-linclust /kaggle/input/cafa-6-protein-function-prediction/Train/train_sequences.fasta ./data/splits/train tmp --min-seq-id 0.3 --cov-mode 1 -c 0.8 \n\nMMseqs Version:                     \tbd01c2229f027d8d8e61947f44d11ef1a7669212\nCluster mode                        \t0\nMax connected component depth       \t1000\nSimilarity type                     \t2\nThreads                             \t4\nCompressed                          \t0\nVerbosity                           \t3\nWeight file name                    \t\nCluster Weight threshold            \t0.9\nSet mode                            \tfalse\nSubstitution matrix                 \taa:blosum62.out,nucl:nucleotide.out\nAdd backtrace                       \tfalse\nAlignment mode                      \t0\nAlignment mode                      \t0\nAllow wrapped scoring               \tfalse\nE-value threshold                   \t0.001\nSeq. id. threshold                  \t0.3\nMin alignment length                \t0\nSeq. id. mode                       \t0\nAlternative alignments              \t0\nCoverage threshold                  \t0.8\nCoverage mode                       \t1\nMax sequence length                 \t65535\nCompositional bias                  \t1\nCompositional bias scale            \t1\nMax reject                          \t2147483647\nMax accept                          \t2147483647\nInclude identical seq. id.          \tfalse\nPreload mode                        \t0\nPseudo count a                      \tsubstitution:1.100,context:1.400\nPseudo count b                      \tsubstitution:4.100,context:5.800\nScore bias                          \t0\nRealign hits                        \tfalse\nRealign score bias                  \t-0.2\nRealign max seqs                    \t2147483647\nCorrelation score weight            \t0\nGap open cost                       \taa:11,nucl:5\nGap extension cost                  \taa:1,nucl:2\nZdrop                               \t40\nAlphabet size                       \taa:21,nucl:5\nk-mers per sequence                 \t21\nSpaced k-mers                       \t0\nSpaced k-mer pattern                \t\nScale k-mers per sequence           \taa:0.000,nucl:0.200\nAdjust k-mer length                 \tfalse\nMask residues                       \t1\nMask residues probability           \t0.9\nMask lower case residues            \t0\nMask lower letter repeating N times \t0\nk-mer length                        \t0\nShift hash                          \t67\nSplit memory limit                  \t0\nInclude only extendable             \tfalse\nSkip repeating k-mers               \tfalse\nRescore mode                        \t0\nRemove hits by seq. id. and coverage\tfalse\nSort results                        \t0\nRemove temporary files              \ttrue\nForce restart with latest tmp       \tfalse\nMPI runner                          \t\nDatabase type                       \t0\nShuffle input database              \ttrue\nCreatedb mode                       \t1\nWrite lookup file                   \t0\nOffset of numeric ids               \t0\nUse GPU                             \t0\n\ncreatedb /kaggle/input/cafa-6-protein-function-prediction/Train/train_sequences.fasta tmp/2666752572842936744/input --createdb-mode 1 --write-lookup 0 \n\n\u001b[33mShuffle database cannot be combined with --createdb-mode 1\n\u001b[39m\u001b[33mWe recompute with --shuffle 0\n\u001b[39mConverting sequences\n\u001b[33mMultiline fasta can not be combined with --createdb-mode 0\n\u001b[39m\u001b[33mWe recompute with --createdb-mode 1\n\u001b[39mTime for merging to input_h: 0h 0m 0s 0ms\nTime for merging to input: 0h 0m 0s 0ms\n[82316] 1s 183ms\nTime for merging to input_h: 0h 0m 0s 6ms\nTime for merging to input: 0h 0m 0s 27ms\nDatabase type: Aminoacid\nTime for processing: 0h 0m 1s 231ms\nCreate directory tmp/2666752572842936744/clu_tmp\nlinclust tmp/2666752572842936744/input tmp/2666752572842936744/clu tmp/2666752572842936744/clu_tmp -e 0.001 --min-seq-id 0.3 -c 0.8 --cov-mode 1 --spaced-kmer-mode 0 --remove-tmp-files 1 \n\nSet cluster mode GREEDY MEM.\nkmermatcher tmp/2666752572842936744/input tmp/2666752572842936744/clu_tmp/8872536190024565876/pref --sub-mat 'aa:blosum62.out,nucl:nucleotide.out' --alph-size aa:13,nucl:5 --min-seq-id 0.3 --kmer-per-seq 21 --spaced-kmer-mode 0 --kmer-per-seq-scale aa:0.000,nucl:0.200 --adjust-kmer-len 0 --mask 0 --mask-prob 0.9 --mask-lower-case 0 --mask-n-repeat 0 --cov-mode 1 -k 0 -c 0.8 --max-seq-len 65535 --hash-shift 67 --split-memory-limit 0 --include-only-extendable 0 --ignore-multi-kmer 0 --threads 4 --compressed 0 -v 3 --cluster-weight-threshold 0.9 \n\nkmermatcher tmp/2666752572842936744/input tmp/2666752572842936744/clu_tmp/8872536190024565876/pref --sub-mat 'aa:blosum62.out,nucl:nucleotide.out' --alph-size aa:13,nucl:5 --min-seq-id 0.3 --kmer-per-seq 21 --spaced-kmer-mode 0 --kmer-per-seq-scale aa:0.000,nucl:0.200 --adjust-kmer-len 0 --mask 0 --mask-prob 0.9 --mask-lower-case 0 --mask-n-repeat 0 --cov-mode 1 -k 0 -c 0.8 --max-seq-len 65535 --hash-shift 67 --split-memory-limit 0 --include-only-extendable 0 --ignore-multi-kmer 0 --threads 4 --compressed 0 -v 3 --cluster-weight-threshold 0.9 \n\nDatabase size: 82404 type: Aminoacid\nReduced amino acid alphabet: (A S T) (C) (D B N) (E Q Z) (F Y) (G) (H) (I V) (K R) (L J M) (P) (W) (X) \n\nGenerate k-mers list for 1 split\n[=================================================================] 100.00% 82.40K 0s 624ms    \nSort kmer 0h 0m 0s 111ms\nSort by rep. sequence 0h 0m 0s 36ms\nTime for fill: 0h 0m 0s 14ms\nTime for merging to pref: 0h 0m 0s 0ms\nTime for processing: 0h 0m 0s 846ms\nrescorediagonal tmp/2666752572842936744/input tmp/2666752572842936744/input tmp/2666752572842936744/clu_tmp/8872536190024565876/pref tmp/2666752572842936744/clu_tmp/8872536190024565876/pref_rescore1 --sub-mat 'aa:blosum62.out,nucl:nucleotide.out' --rescore-mode 0 --wrapped-scoring 0 --filter-hits 0 -e 0.001 -c 0.8 -a 0 --cov-mode 1 --min-seq-id 0.5 --min-aln-len 0 --seq-id-mode 0 --add-self-matches 0 --sort-results 0 --db-load-mode 0 --threads 4 --compressed 0 -v 3 \n\n[=================================================================] 100.00% 82.40K 0s 50ms     \nTime for merging to pref_rescore1: 0h 0m 0s 20ms=================>] 98.71% 81.34K eta 0s       \nTime for processing: 0h 0m 0s 98ms\nclust tmp/2666752572842936744/input tmp/2666752572842936744/clu_tmp/8872536190024565876/pref_rescore1 tmp/2666752572842936744/clu_tmp/8872536190024565876/pre_clust --cluster-mode 3 --max-iterations 1000 --similarity-type 2 --threads 4 --compressed 0 -v 3 --cluster-weight-threshold 0.9 --set-mode 0 \n\nClustering mode: Greedy Low Mem\nTotal time: 0h 0m 0s 27ms\n\nSize of the sequence database: 82404\nSize of the alignment database: 82404\nNumber of clusters: 57846\n\nWriting results 0h 0m 0s 9ms\nTime for merging to pre_clust: 0h 0m 0s 0ms\nTime for processing: 0h 0m 0s 57ms\ncreatesubdb tmp/2666752572842936744/clu_tmp/8872536190024565876/order_redundancy tmp/2666752572842936744/input tmp/2666752572842936744/clu_tmp/8872536190024565876/input_step_redundancy -v 3 --subdb-mode 1 \n\nTime for merging to input_step_redundancy: 0h 0m 0s 0ms\nTime for processing: 0h 0m 0s 14ms\ncreatesubdb tmp/2666752572842936744/clu_tmp/8872536190024565876/order_redundancy tmp/2666752572842936744/clu_tmp/8872536190024565876/pref tmp/2666752572842936744/clu_tmp/8872536190024565876/pref_filter1 -v 3 --subdb-mode 1 \n\nTime for merging to pref_filter1: 0h 0m 0s 0ms\nTime for processing: 0h 0m 0s 18ms\nfilterdb tmp/2666752572842936744/clu_tmp/8872536190024565876/pref_filter1 tmp/2666752572842936744/clu_tmp/8872536190024565876/pref_filter2 --filter-file tmp/2666752572842936744/clu_tmp/8872536190024565876/order_redundancy --threads 4 --compressed 0 -v 3 \n\nFiltering using file(s)\n[=================================================================] 100.00% 57.85K 0s 30ms     \nTime for merging to pref_filter2: 0h 0m 0s 14ms\nTime for processing: 0h 0m 0s 67ms\nrescorediagonal tmp/2666752572842936744/clu_tmp/8872536190024565876/input_step_redundancy tmp/2666752572842936744/clu_tmp/8872536190024565876/input_step_redundancy tmp/2666752572842936744/clu_tmp/8872536190024565876/pref_filter2 tmp/2666752572842936744/clu_tmp/8872536190024565876/pref_rescore2 --sub-mat 'aa:blosum62.out,nucl:nucleotide.out' --rescore-mode 1 --wrapped-scoring 0 --filter-hits 1 -e 0.001 -c 0.8 -a 0 --cov-mode 1 --min-seq-id 0.3 --min-aln-len 0 --seq-id-mode 0 --add-self-matches 0 --sort-results 0 --db-load-mode 0 --threads 4 --compressed 0 -v 3 \n\n[=================================================================] 100.00% 57.85K 0s 58ms     \nTime for merging to pref_rescore2: 0h 0m 0s 15ms================> ] 98.33% 56.88K eta 0s       \nTime for processing: 0h 0m 0s 95ms\nalign tmp/2666752572842936744/clu_tmp/8872536190024565876/input_step_redundancy tmp/2666752572842936744/clu_tmp/8872536190024565876/input_step_redundancy tmp/2666752572842936744/clu_tmp/8872536190024565876/pref_rescore2 tmp/2666752572842936744/clu_tmp/8872536190024565876/aln --sub-mat 'aa:blosum62.out,nucl:nucleotide.out' -a 0 --alignment-mode 2 --alignment-output-mode 0 --wrapped-scoring 0 -e 0.001 --min-seq-id 0.3 --min-aln-len 0 --seq-id-mode 0 --alt-ali 0 -c 0.8 --cov-mode 1 --max-seq-len 65535 --comp-bias-corr 1 --comp-bias-corr-scale 1 --max-rejected 2147483647 --max-accept 2147483647 --add-self-matches 0 --db-load-mode 0 --pca substitution:1.100,context:1.400 --pcb substitution:4.100,context:5.800 --score-bias 0 --realign 0 --realign-score-bias -0.2 --realign-max-seqs 2147483647 --corr-score-weight 0 --gap-open aa:11,nucl:5 --gap-extend aa:1,nucl:2 --zdrop 40 --threads 4 --compressed 0 -v 3 \n\nCompute score and coverage\nQuery database size: 57846 type: Aminoacid\nTarget database size: 57846 type: Aminoacid\nCalculation of alignments\n[=================================================================] 100.00% 57.85K 9s 735ms    \nTime for merging to aln: 0h 0m 0s 16ms\n86017 alignments calculated\n76072 sequence pairs passed the thresholds (0.884383 of overall calculated)\n1.315078 hits per query sequence\nTime for processing: 0h 0m 9s 774ms\nclust tmp/2666752572842936744/clu_tmp/8872536190024565876/input_step_redundancy tmp/2666752572842936744/clu_tmp/8872536190024565876/aln tmp/2666752572842936744/clu_tmp/8872536190024565876/clust --cluster-mode 3 --max-iterations 1000 --similarity-type 2 --threads 4 --compressed 0 -v 3 --cluster-weight-threshold 0.9 --set-mode 0 \n\nClustering mode: Greedy Low Mem\nTotal time: 0h 0m 0s 19ms\n\nSize of the sequence database: 57846\nSize of the alignment database: 57846\nNumber of clusters: 45294\n\nWriting results 0h 0m 0s 8ms\nTime for merging to clust: 0h 0m 0s 0ms\nTime for processing: 0h 0m 0s 41ms\nmergeclusters tmp/2666752572842936744/input tmp/2666752572842936744/clu tmp/2666752572842936744/clu_tmp/8872536190024565876/pre_clust tmp/2666752572842936744/clu_tmp/8872536190024565876/clust --threads 4 --compressed 0 -v 3 \n\nClustering step 1\n[=================================================================] 100.00% 57.85K 0s 16ms     \nClustering step 2\n[=================================================================] 100.00% 45.29K 0s 30ms     \nWrite merged clustering\n[=================================================================] 100.00% 82.40K 0s 50ms     \nTime for merging to clu: 0h 0m 0s 11ms\nTime for processing: 0h 0m 0s 77ms\nrmdb tmp/2666752572842936744/clu_tmp/8872536190024565876/pref_filter1 -v 3 \n\nTime for processing: 0h 0m 0s 0ms\nrmdb tmp/2666752572842936744/clu_tmp/8872536190024565876/pref -v 3 \n\nTime for processing: 0h 0m 0s 0ms\nrmdb tmp/2666752572842936744/clu_tmp/8872536190024565876/pref_rescore1 -v 3 \n\nTime for processing: 0h 0m 0s 0ms\nrmdb tmp/2666752572842936744/clu_tmp/8872536190024565876/pre_clust -v 3 \n\nTime for processing: 0h 0m 0s 0ms\nrmdb tmp/2666752572842936744/clu_tmp/8872536190024565876/input_step_redundancy -v 3 \n\nTime for processing: 0h 0m 0s 0ms\nrmdb tmp/2666752572842936744/clu_tmp/8872536190024565876/input_step_redundancy_h -v 3 \n\nTime for processing: 0h 0m 0s 0ms\nrmdb tmp/2666752572842936744/clu_tmp/8872536190024565876/pref_filter2 -v 3 \n\nTime for processing: 0h 0m 0s 0ms\nrmdb tmp/2666752572842936744/clu_tmp/8872536190024565876/pref_rescore2 -v 3 \n\nTime for processing: 0h 0m 0s 0ms\nrmdb tmp/2666752572842936744/clu_tmp/8872536190024565876/aln -v 3 \n\nTime for processing: 0h 0m 0s 0ms\nrmdb tmp/2666752572842936744/clu_tmp/8872536190024565876/clust -v 3 \n\nTime for processing: 0h 0m 0s 0ms\ncreatetsv tmp/2666752572842936744/input tmp/2666752572842936744/input tmp/2666752572842936744/clu tmp/2666752572842936744/cluster.tsv --threads 4 -v 3 \n\nTime for merging to cluster.tsv: 0h 0m 0s 14ms\nTime for processing: 0h 0m 0s 60ms\nresult2repseq tmp/2666752572842936744/input tmp/2666752572842936744/clu tmp/2666752572842936744/clu_rep --db-load-mode 0 --compressed 0 --threads 4 -v 3 \n\n[=================================================================] 100.00% 45.29K 0s 20ms     \nTime for merging to clu_rep: 0h 0m 0s 31ms\nTime for processing: 0h 0m 0s 86ms\nresult2flat tmp/2666752572842936744/input tmp/2666752572842936744/input tmp/2666752572842936744/clu_rep tmp/2666752572842936744/rep_seq.fasta --use-fasta-header -v 3 \n\nTime for processing: 0h 0m 0s 122ms\ncreateseqfiledb tmp/2666752572842936744/input tmp/2666752572842936744/clu tmp/2666752572842936744/clu_seqs --threads 4 -v 3 \n\n[=================================================================] 100.00% 45.29K 0s 42ms     \nTime for merging to clu_seqs: 0h 0m 0s 11ms\nTime for processing: 0h 0m 0s 110ms\nresult2flat tmp/2666752572842936744/input tmp/2666752572842936744/input tmp/2666752572842936744/clu_seqs tmp/2666752572842936744/all_seqs.fasta -v 3 \n\nTime for processing: 0h 0m 0s 219ms\nrmdb tmp/2666752572842936744/input -v 3 \n\nTime for processing: 0h 0m 0s 6ms\nrmdb tmp/2666752572842936744/input_h -v 3 \n\nTime for processing: 0h 0m 0s 1ms\nrmdb tmp/2666752572842936744/clu_seqs -v 3 \n\nTime for processing: 0h 0m 0s 8ms\nrmdb tmp/2666752572842936744/clu_rep -v 3 \n\nTime for processing: 0h 0m 0s 4ms\nrmdb tmp/2666752572842936744/clu -v 3 \n\nTime for processing: 0h 0m 0s 0ms\nA0A0C5B5G6\tA0A0C5B5G6\nA0JNW5\tA0JNW5\nA0PK11\tA0PK11\nA0PK11\tB2RVW2\nA1L190\tA1L190\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"# Data Processing - Embedding Extraction","metadata":{"id":"UoZ3HKtSBzbx"}},{"cell_type":"code","source":"# Run embedding extraction\n# This takes time! (Approx 3-5 hours for full CAFA train set on T4)\n!python src/extract_embeddings.py \\\n    --fasta /kaggle/input/cafa-6-protein-function-prediction/Train/train_sequences.fasta \\\n    --output ./data/embeddings/train \\\n    --model facebook/esm2_t33_650M_UR50D","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m-icyWGWBzHD","outputId":"db097fed-4fb8-4efd-d60c-1837b665eedd","trusted":true,"execution":{"iopub.status.busy":"2026-01-25T08:02:47.705816Z","iopub.execute_input":"2026-01-25T08:02:47.706104Z","iopub.status.idle":"2026-01-25T08:20:47.843659Z","shell.execute_reply.started":"2026-01-25T08:02:47.706060Z","shell.execute_reply":"2026-01-25T08:20:47.842747Z"}},"outputs":[{"name":"stdout","text":"Reading FASTA file: /kaggle/input/cafa-6-protein-function-prediction/Train/train_sequences.fasta\nTotal sequences: 82404\nFound 2 GPUs. Spawning workers...\n[GPU 0] Initializing model facebook/esm2_t33_650M_UR50D...\n[GPU 0] Processing indices 0 to 41202 (41202 sequences)\ntokenizer_config.json: 100%|██████████████████| 95.0/95.0 [00:00<00:00, 597kB/s]\nvocab.txt: 100%|██████████████████████████████| 93.0/93.0 [00:00<00:00, 508kB/s]\nspecial_tokens_map.json: 100%|██████████████████| 125/125 [00:00<00:00, 697kB/s]\nconfig.json: 100%|█████████████████████████████| 724/724 [00:00<00:00, 3.56MB/s]\n2026-01-25 08:03:09.024728: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1769328189.206618     219 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1769328189.260007     219 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1769328189.707251     219 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769328189.707298     219 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769328189.707302     219 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769328189.707306     219 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n[GPU 1] Initializing model facebook/esm2_t33_650M_UR50D...\n[GPU 1] Processing indices 41202 to 82404 (41202 sequences)\n2026-01-25 08:03:13.069665: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1769328193.091364     234 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1769328193.097878     234 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1769328193.115249     234 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769328193.115276     234 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769328193.115280     234 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769328193.115283     234 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nmodel.safetensors: 100%|████████████████████| 2.61G/2.61G [00:07<00:00, 363MB/s]\nSome weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nGPU 0:  19%|█████▍                      | 7924/41202 [00:00<00:00, 79227.80it/s]\nGPU 0:  39%|██████████▌                | 16168/41202 [00:00<00:00, 81112.82it/s]\u001b[A\nGPU 0:  59%|███████████████▉           | 24280/41202 [00:00<00:00, 79750.68it/s]\u001b[A\nGPU 0:  79%|█████████████████████▏     | 32394/41202 [00:00<00:00, 80290.41it/s]\u001b[A\nGPU 1:  60%|████████████████▏          | 24693/41202 [00:00<00:00, 82801.24it/s]\u001b[A\nGPU 1: 100%|███████████████████████████| 41202/41202 [00:00<00:00, 81998.61it/s]\u001b[A\n[GPU 1] Finished. Processed 0 sequences.\nGPU 0: 100%|██████████████████████████████| 41202/41202 [17:12<00:00, 39.90it/s]\n[GPU 0] Finished. Processed 4048 sequences.\nAll extraction processes completed.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"# Zip the Results","metadata":{}},{"cell_type":"code","source":"# --- Configuration ---\n# Ensure these match where you downloaded/unzipped the data\nOUTPUT_DIR = \"data/embeddings/\"\nZIP_NAME = \"esm2_650m_train_embeddings.zip\"\n\nif os.path.exists(OUTPUT_DIR) and len(os.listdir(OUTPUT_DIR)) > 0:\n    print(f\"Zipping files to {ZIP_NAME}...\")\n    # -q for quiet, -r for recursive, -j to junk paths (optional, but -r preserves structure)\n    !zip -q -r {ZIP_NAME} {OUTPUT_DIR}\n    \n    print(f\"Success! '{ZIP_NAME}' is ready in /kaggle/working/\")\n    print(\"To keep this file permanently: Click 'Save Version' -> 'Save & Run All' or 'Quick Save'.\")\n    \n    # Optional: Clean up raw .pt files to save disk space if you are running low\n    # !rm -rf {OUTPUT_DIR}\nelse:\n    print(\"Error: Output directory is empty or does not exist.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-25T08:21:11.530777Z","iopub.execute_input":"2026-01-25T08:21:11.531005Z","iopub.status.idle":"2026-01-25T08:21:31.816768Z","shell.execute_reply.started":"2026-01-25T08:21:11.530976Z","shell.execute_reply":"2026-01-25T08:21:31.815775Z"}},"outputs":[{"name":"stdout","text":"Zipping files to esm2_650m_train_embeddings.zip...\nSuccess! 'esm2_650m_train_embeddings.zip' is ready in /kaggle/working/\nTo keep this file permanently: Click 'Save Version' -> 'Save & Run All' or 'Quick Save'.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"# Renaming the embeddings","metadata":{}},{"cell_type":"code","source":"import os\nfrom pathlib import Path\nfrom tqdm import tqdm\n\n# Paths\nEMBED_DIR = Path(\"data/embeddings/train\")\nCLUSTER_FILE = Path(\"data/splits/train_cluster.tsv\")\nCLUSTER_FILE_NEW = Path(\"data/splits/train_cluster_fixed.tsv\")\n\ndef clean_id(header_str):\n    \"\"\"\n    Parses 'sp|Q497K5|ARRD5_MOUSE' -> 'Q497K5'\n    Parses 'tr|A0A024RBG1|...' -> 'A0A024RBG1'\n    Returns original if no pipes found.\n    \"\"\"\n    header_str = str(header_str).strip()\n    if header_str.count('|') >= 2:\n        return header_str.split('|')[1]\n    return header_str\n\nprint(\"1. Normalizing Embedding Filenames...\")\nfiles = list(EMBED_DIR.glob(\"*.pt\"))\nrenamed_count = 0\n\nfor file_path in tqdm(files):\n    old_name = file_path.stem # e.g., sp|Q497K5|ARRD5_MOUSE\n    new_id = clean_id(old_name)\n    \n    if new_id != old_name:\n        new_path = file_path.with_name(f\"{new_id}.pt\")\n        # Rename (overwrite if exists, though unlikely in this batch)\n        file_path.rename(new_path)\n        renamed_count += 1\n\nprint(f\"Renamed {renamed_count} embedding files.\")\n\nprint(\"\\n2. Normalizing Cluster File...\")\nif CLUSTER_FILE.exists():\n    with open(CLUSTER_FILE, 'r') as f_in, open(CLUSTER_FILE_NEW, 'w') as f_out:\n        for line in f_in:\n            parts = line.strip().split('\\t')\n            if len(parts) >= 2:\n                # Clean both representative and member\n                rep = clean_id(parts[0])\n                member = clean_id(parts[1])\n                f_out.write(f\"{rep}\\t{member}\\n\")\n    \n    # Replace old cluster file\n    os.replace(CLUSTER_FILE_NEW, CLUSTER_FILE)\n    print(f\"Fixed IDs in {CLUSTER_FILE}\")\nelse:\n    print(f\"Warning: {CLUSTER_FILE} not found. Run the mmseqs step first?\")\n\nprint(\"\\nID Normalization Complete. You can now run main.py.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-26T04:24:33.437681Z","iopub.execute_input":"2026-01-26T04:24:33.437996Z","iopub.status.idle":"2026-01-26T04:24:35.711489Z","shell.execute_reply.started":"2026-01-26T04:24:33.437972Z","shell.execute_reply":"2026-01-26T04:24:35.710896Z"}},"outputs":[{"name":"stdout","text":"1. Normalizing Embedding Filenames...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 82404/82404 [00:01<00:00, 49981.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Renamed 82404 embedding files.\n\n2. Normalizing Cluster File...\nFixed IDs in data/splits/train_cluster.tsv\n\nID Normalization Complete. You can now run main.py.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# Train the model","metadata":{"id":"diS9TaQcF7jo"}},{"cell_type":"code","source":"!python src/main.py \\\n    --obo_path /kaggle/input/cafa-6-protein-function-prediction/Train/go-basic.obo \\\n    --annotations_path /kaggle/input/cafa-6-protein-function-prediction/Train/train_terms.tsv \\\n    --cluster_path /kaggle/working/data/splits/train_cluster.tsv \\\n    --embedding_dir /kaggle/working/data/embeddings/train \\\n    --output_dir ./results/final_run \\\n    --input_dim 1280 \\\n    --batch_size 512 \\\n    --epochs 75 \\\n    --use_pos_weights \\\n    --use_amp ","metadata":{"id":"-eQydQgAF6u1","trusted":true,"execution":{"iopub.status.busy":"2026-01-26T04:38:10.345355Z","iopub.execute_input":"2026-01-26T04:38:10.346207Z","iopub.status.idle":"2026-01-26T04:52:42.203905Z","shell.execute_reply.started":"2026-01-26T04:38:10.346170Z","shell.execute_reply":"2026-01-26T04:52:42.202936Z"}},"outputs":[{"name":"stdout","text":"Using 2 GPUs!\nLoading GO graph from /kaggle/input/cafa-6-protein-function-prediction/Train/go-basic.obo...\nLoaded GO graph with 40122 terms.\nBuilding label vocabulary with min_frequency=50...\nTerms meeting min_frequency threshold: 5604\nReading cluster file: /kaggle/working/data/splits/train_cluster.tsv\nFound 45294 clusters containing 82404 sequences\nSplit complete: Train 66033, Val 16371\nDataset initialized with 66033 proteins\nDataset initialized with 16371 proteins\nCalculating positive class weights...\nComputing weights: 100%|██████████████████████| 258/258 [00:41<00:00,  6.21it/s]\nWrapping model in DataParallel (Batch size 512 will be split across GPUs)\nEpoch 1 - Train: 0.6989, Val: 0.5726                                            \nEpoch 2 - Train: 0.5442, Val: 0.5068                                            \nEpoch 3 - Train: 0.4945, Val: 0.4730                                            \nEpoch 4 - Train: 0.4649, Val: 0.4517                                            \nEpoch 5 - Train: 0.4440, Val: 0.4369                                            \nEpoch 6 - Train: 0.4279, Val: 0.4251                                            \nEpoch 7 - Train: 0.4152, Val: 0.4163                                            \nEpoch 8 - Train: 0.4043, Val: 0.4098                                            \nEpoch 9 - Train: 0.3951, Val: 0.4039                                            \nEpoch 10 - Train: 0.3871, Val: 0.3999                                           \nEpoch 11 - Train: 0.3798, Val: 0.3951                                           \nEpoch 12 - Train: 0.3733, Val: 0.3923                                           \nEpoch 13 - Train: 0.3672, Val: 0.3895                                           \nEpoch 14 - Train: 0.3614, Val: 0.3869                                           \nEpoch 15 - Train: 0.3565, Val: 0.3840                                           \nEpoch 16 - Train: 0.3520, Val: 0.3828                                           \nEpoch 17 - Train: 0.3473, Val: 0.3806                                           \nEpoch 18 - Train: 0.3432, Val: 0.3794                                           \nEpoch 19 - Train: 0.3389, Val: 0.3781                                           \nEpoch 20 - Train: 0.3350, Val: 0.3785                                           \nEpoch 21 - Train: 0.3316, Val: 0.3772                                           \nEpoch 22 - Train: 0.3276, Val: 0.3761                                           \nEpoch 23 - Train: 0.3243, Val: 0.3738                                           \nEpoch 24 - Train: 0.3210, Val: 0.3742                                           \nEpoch 25 - Train: 0.3181, Val: 0.3721                                           \nEpoch 26 - Train: 0.3147, Val: 0.3727                                           \nEpoch 27 - Train: 0.3121, Val: 0.3721                                           \nEpoch 28 - Train: 0.3090, Val: 0.3722                                           \nEpoch 29 - Train: 0.3062, Val: 0.3744                                           \nEpoch 30 - Train: 0.3038, Val: 0.3723                                           \nEpoch 31 - Train: 0.2994, Val: 0.3728                                           \nEpoch 32 - Train: 0.2979, Val: 0.3724                                           \nEarly stopping triggered.\nLoading best model weights...\nLoading best model for optimization...\nOptimizing Per-Class Thresholds\nCollecting predictions: 100%|███████████████████| 32/32 [00:04<00:00,  7.01it/s]\nOptimizing: 100%|██████████████████████████| 5604/5604 [00:25<00:00, 223.08it/s]\nCollecting predictions: 100%|███████████████████| 32/32 [00:04<00:00,  6.99it/s]\nEvaluation - Micro F1: 0.3487, Macro F1: 0.2027\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"### ","metadata":{}},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"%%writefile src/inference.py\nimport os\nimport argparse\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.multiprocessing as mp\nimport numpy as np\nimport gc\nfrom pathlib import Path\nfrom transformers import AutoTokenizer, AutoModel\nfrom Bio import SeqIO\nfrom tqdm import tqdm\n\n# Import your model definition\nfrom model import ProteinMLP\n\n# Configuration\nMAX_SEQUENCE_LENGTH = 1022\nTHRESHOLD = 0.01\nBATCH_SIZE = 100  # Number of sequences to process before saving to disk\n\ndef get_device(gpu_id):\n    return f\"cuda:{gpu_id}\"\n\ndef clean_id(header_str):\n    header_str = str(header_str).strip()\n    if header_str.count('|') >= 2:\n        return header_str.split('|')[1]\n    return header_str.split()[0]\n\ndef load_artifacts(model_dir):\n    \"\"\"Load vocabulary and model config\"\"\"\n    model_dir = Path(model_dir)\n    \n    # Load Vocabulary\n    vocab_path = model_dir / \"vocabulary.npz\"\n    data = np.load(vocab_path, allow_pickle=True)\n    valid_terms = data['valid_terms']\n    index_to_term = {i: term for i, term in enumerate(valid_terms)}\n    \n    # Load Checkpoint to get config/weights\n    checkpoint_path = model_dir / \"best_model.pt\"\n    checkpoint = torch.load(checkpoint_path, map_location=\"cpu\")\n    config = checkpoint.get('config', {})\n    \n    return index_to_term, config, checkpoint['model_state_dict']\n\ndef worker_process(gpu_id, all_records, model_dir, esm_model_name, hidden_dim, output_dir):\n    device = get_device(gpu_id)\n    print(f\"[GPU {gpu_id}] Worker started.\")\n    \n    # 1. Calculate Slice for this GPU\n    total_records = len(all_records)\n    n_gpus = torch.cuda.device_count()\n    if n_gpus == 0: n_gpus = 1\n    \n    chunk_size = math.ceil(total_records / n_gpus)\n    start_idx = gpu_id * chunk_size\n    end_idx = min(start_idx + chunk_size, total_records)\n    \n    my_records = all_records[start_idx:end_idx]\n    \n    # 2. Setup Batches\n    num_batches = math.ceil(len(my_records) / BATCH_SIZE)\n    print(f\"[GPU {gpu_id}] Processing {len(my_records)} seqs in {num_batches} batches.\")\n    \n    # 3. Load Artifacts & Model\n    # We load strictly inside the worker to avoid pickling issues\n    index_to_term, config, state_dict = load_artifacts(model_dir)\n    input_dim = config.get('input_dim', 1280) \n    num_classes = config.get('num_classes', len(index_to_term))\n    \n    tokenizer = AutoTokenizer.from_pretrained(esm_model_name)\n    esm_model = AutoModel.from_pretrained(esm_model_name).to(device)\n    esm_model.eval()\n    \n    mlp = ProteinMLP(num_classes=num_classes, input_dim=input_dim, hidden_dim=hidden_dim)\n    \n    # Clean state dict keys\n    new_state_dict = {}\n    for k, v in state_dict.items():\n        name = k[7:] if k.startswith('module.') else k\n        new_state_dict[name] = v\n    mlp.load_state_dict(new_state_dict)\n    mlp = mlp.to(device)\n    mlp.eval()\n    \n    # 4. Batch Processing Loop\n    for i in range(num_batches):\n        batch_filename = os.path.join(output_dir, f\"batch_gpu{gpu_id}_{i}.tsv\")\n        \n        # RESUME CAPABILITY: Skip if file exists and is not empty\n        if os.path.exists(batch_filename) and os.path.getsize(batch_filename) > 0:\n            # Only print every 10th skipped batch to reduce clutter\n            if i % 10 == 0:\n                print(f\"[GPU {gpu_id}] Skipping batch {i}/{num_batches} (already exists)\")\n            continue\n            \n        # Get batch sequences\n        b_start = i * BATCH_SIZE\n        b_end = min(b_start + BATCH_SIZE, len(my_records))\n        batch_records = my_records[b_start:b_end]\n        \n        batch_lines = []\n        \n        # Process individual sequences in this batch\n        # (We could batch-tokenize here for more speed, but let's keep it safe for VRAM)\n        for record in batch_records:\n            protein_id = clean_id(record.id)\n            sequence = str(record.seq)\n            if len(sequence) > MAX_SEQUENCE_LENGTH:\n                sequence = sequence[:MAX_SEQUENCE_LENGTH]\n                \n            try:\n                # Embed\n                inputs = tokenizer(sequence, return_tensors=\"pt\", padding=False, truncation=True, max_length=MAX_SEQUENCE_LENGTH+2)\n                inputs = {k: v.to(device) for k, v in inputs.items()}\n                \n                with torch.no_grad():\n                    esm_out = esm_model(**inputs)\n                    embedding = esm_out.last_hidden_state[:, 1:-1, :].mean(dim=1)\n                    \n                    # Predict\n                    logits = mlp(embedding)\n                    probs = torch.sigmoid(logits).cpu().numpy()[0]\n                \n                # Filter\n                mask = probs >= THRESHOLD\n                indices = np.where(mask)[0]\n                \n                for idx in indices:\n                    batch_lines.append(f\"{protein_id}\\t{index_to_term[idx]}\\t{probs[idx]:.3f}\\n\")\n                \n                # Explicit cleanup to prevent memory leaks\n                del inputs, esm_out, embedding, logits, probs\n                \n            except Exception as e:\n                print(f\"[GPU {gpu_id}] Error on {protein_id}: {e}\")\n        \n        # Write Batch to Disk\n        with open(batch_filename, 'w') as f_out:\n            if batch_lines:\n                f_out.writelines(batch_lines)\n            else:\n                # Create empty file to mark progress even if no preds found\n                f_out.write(\"\") \n        \n        # Aggressive Garbage Collection\n        if i % 5 == 0:\n            gc.collect()\n            torch.cuda.empty_cache()\n            \n        print(f\"[GPU {gpu_id}] Completed batch {i}/{num_batches}\")\n\n    print(f\"[GPU {gpu_id}] Finished.\")\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--fasta\", required=True)\n    parser.add_argument(\"--model_dir\", required=True)\n    parser.add_argument(\"--output\", default=\"submission.tsv\")\n    parser.add_argument(\"--esm_model\", default=\"facebook/esm2_t33_650M_UR50D\")\n    parser.add_argument(\"--hidden_dim\", type=int, default=1024)\n    args = parser.parse_args()\n    \n    # Setup Temporary Directory for Batches\n    temp_dir = \"temp_inference_batches\"\n    os.makedirs(temp_dir, exist_ok=True)\n    \n    print(f\"Reading {args.fasta}...\")\n    all_records = list(SeqIO.parse(args.fasta, \"fasta\"))\n    n_gpus = torch.cuda.device_count()\n    \n    if n_gpus == 0:\n        print(\"No GPUs found. Running on CPU.\")\n        worker_process(0, all_records, args.model_dir, args.esm_model, args.hidden_dim, temp_dir)\n    else:\n        mp.spawn(\n            worker_process,\n            args=(all_records, args.model_dir, args.esm_model, args.hidden_dim, temp_dir),\n            nprocs=n_gpus,\n            join=True\n        )\n    \n    # Optional cleanup (commented out to be safe)\n    # import shutil\n    # shutil.rmtree(temp_dir)\n                \n    print(f\"Submission saved to {args.output}\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-27T15:55:41.587011Z","iopub.execute_input":"2026-01-27T15:55:41.587499Z","iopub.status.idle":"2026-01-27T15:55:41.596425Z","shell.execute_reply.started":"2026-01-27T15:55:41.587461Z","shell.execute_reply":"2026-01-27T15:55:41.595689Z"}},"outputs":[{"name":"stdout","text":"Overwriting src/inference.py\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"!python src/inference.py \\\n    --fasta /kaggle/input/cafa-6-protein-function-prediction/Test/testsuperset.fasta \\\n    --model_dir results/final_run \\\n    --output submission.tsv \\\n    --esm_model facebook/esm2_t33_650M_UR50D \\\n    --hidden_dim 512","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T07:58:22.627375Z","iopub.execute_input":"2026-01-28T07:58:22.627933Z","iopub.status.idle":"2026-01-28T09:53:03.269626Z","shell.execute_reply.started":"2026-01-28T07:58:22.627893Z","shell.execute_reply":"2026-01-28T09:53:03.268923Z"}},"outputs":[{"name":"stdout","text":"Reading /kaggle/input/cafa-6-protein-function-prediction/Test/testsuperset.fasta...\n[GPU 0] Worker started.\n[GPU 0] Processing 112155 seqs in 1122 batches.\ntokenizer_config.json: 100%|██████████████████| 95.0/95.0 [00:00<00:00, 473kB/s]\nvocab.txt: 100%|██████████████████████████████| 93.0/93.0 [00:00<00:00, 654kB/s]\nspecial_tokens_map.json: 100%|██████████████████| 125/125 [00:00<00:00, 798kB/s]\nconfig.json: 100%|█████████████████████████████| 724/724 [00:00<00:00, 4.72MB/s]\n2026-01-28 07:58:50.135012: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1769587130.392058     128 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1769587130.463670     128 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1769587131.036531     128 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769587131.036587     128 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769587131.036592     128 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769587131.036598     128 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n[GPU 1] Worker started.\n[GPU 1] Processing 112154 seqs in 1122 batches.\n2026-01-28 07:58:54.426869: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1769587134.448799     143 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1769587134.455357     143 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1769587134.472199     143 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769587134.472230     143 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769587134.472234     143 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769587134.472237     143 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nmodel.safetensors: 100%|████████████████████| 2.61G/2.61G [00:09<00:00, 282MB/s]\nSome weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n[GPU 0] Skipping batch 0/1122 (already exists)\n[GPU 0] Skipping batch 10/1122 (already exists)\n[GPU 0] Skipping batch 20/1122 (already exists)\n[GPU 0] Skipping batch 30/1122 (already exists)\n[GPU 0] Skipping batch 40/1122 (already exists)\n[GPU 0] Skipping batch 50/1122 (already exists)\n[GPU 0] Skipping batch 60/1122 (already exists)\n[GPU 0] Skipping batch 70/1122 (already exists)\n[GPU 0] Skipping batch 80/1122 (already exists)\n[GPU 0] Skipping batch 90/1122 (already exists)\n[GPU 0] Skipping batch 100/1122 (already exists)\n[GPU 0] Skipping batch 110/1122 (already exists)\n[GPU 0] Skipping batch 120/1122 (already exists)\n[GPU 0] Skipping batch 130/1122 (already exists)\n[GPU 0] Skipping batch 140/1122 (already exists)\n[GPU 0] Skipping batch 150/1122 (already exists)\n[GPU 0] Skipping batch 160/1122 (already exists)\n[GPU 0] Skipping batch 170/1122 (already exists)\n[GPU 0] Skipping batch 180/1122 (already exists)\n[GPU 0] Skipping batch 190/1122 (already exists)\n[GPU 0] Skipping batch 200/1122 (already exists)\n[GPU 0] Skipping batch 210/1122 (already exists)\n[GPU 0] Skipping batch 220/1122 (already exists)\n[GPU 0] Skipping batch 230/1122 (already exists)\n[GPU 0] Skipping batch 240/1122 (already exists)\n[GPU 0] Skipping batch 250/1122 (already exists)\n[GPU 0] Skipping batch 260/1122 (already exists)\n[GPU 0] Skipping batch 270/1122 (already exists)\n[GPU 0] Skipping batch 280/1122 (already exists)\n[GPU 0] Skipping batch 290/1122 (already exists)\n[GPU 0] Skipping batch 300/1122 (already exists)\n[GPU 0] Skipping batch 310/1122 (already exists)\n[GPU 0] Skipping batch 320/1122 (already exists)\n[GPU 0] Skipping batch 330/1122 (already exists)\n[GPU 0] Skipping batch 340/1122 (already exists)\n[GPU 0] Skipping batch 350/1122 (already exists)\n[GPU 0] Skipping batch 360/1122 (already exists)\n[GPU 0] Skipping batch 370/1122 (already exists)\n[GPU 0] Skipping batch 380/1122 (already exists)\n[GPU 0] Skipping batch 390/1122 (already exists)\n[GPU 0] Skipping batch 400/1122 (already exists)\n[GPU 0] Skipping batch 410/1122 (already exists)\n[GPU 0] Skipping batch 420/1122 (already exists)\n[GPU 0] Skipping batch 430/1122 (already exists)\n[GPU 0] Skipping batch 440/1122 (already exists)\n[GPU 0] Skipping batch 450/1122 (already exists)\n[GPU 0] Skipping batch 460/1122 (already exists)\n[GPU 0] Skipping batch 470/1122 (already exists)\n[GPU 0] Skipping batch 480/1122 (already exists)\n[GPU 0] Skipping batch 490/1122 (already exists)\n[GPU 0] Skipping batch 500/1122 (already exists)\n[GPU 0] Skipping batch 510/1122 (already exists)\n[GPU 0] Skipping batch 520/1122 (already exists)\n[GPU 0] Skipping batch 530/1122 (already exists)\n[GPU 0] Skipping batch 540/1122 (already exists)\n[GPU 0] Skipping batch 550/1122 (already exists)\n[GPU 0] Skipping batch 560/1122 (already exists)\n[GPU 0] Skipping batch 570/1122 (already exists)\n[GPU 0] Skipping batch 580/1122 (already exists)\n[GPU 0] Skipping batch 590/1122 (already exists)\n[GPU 0] Skipping batch 600/1122 (already exists)\n[GPU 0] Skipping batch 610/1122 (already exists)\n[GPU 0] Skipping batch 620/1122 (already exists)\n[GPU 0] Skipping batch 630/1122 (already exists)\n[GPU 0] Skipping batch 640/1122 (already exists)\n[GPU 0] Skipping batch 650/1122 (already exists)\n[GPU 0] Skipping batch 660/1122 (already exists)\n[GPU 0] Skipping batch 670/1122 (already exists)\n[GPU 0] Skipping batch 680/1122 (already exists)\n[GPU 0] Skipping batch 690/1122 (already exists)\n[GPU 0] Skipping batch 700/1122 (already exists)\n[GPU 0] Skipping batch 710/1122 (already exists)\n[GPU 0] Skipping batch 720/1122 (already exists)\n[GPU 0] Skipping batch 730/1122 (already exists)\n[GPU 0] Skipping batch 740/1122 (already exists)\n[GPU 0] Skipping batch 750/1122 (already exists)\n[GPU 0] Skipping batch 760/1122 (already exists)\n[GPU 0] Skipping batch 770/1122 (already exists)\n[GPU 0] Skipping batch 780/1122 (already exists)\n[GPU 0] Skipping batch 790/1122 (already exists)\n[GPU 0] Skipping batch 800/1122 (already exists)\n[GPU 0] Skipping batch 810/1122 (already exists)\n[GPU 0] Skipping batch 820/1122 (already exists)\n[GPU 0] Skipping batch 830/1122 (already exists)\n[GPU 0] Skipping batch 840/1122 (already exists)\n[GPU 1] Skipping batch 0/1122 (already exists)\n[GPU 1] Skipping batch 10/1122 (already exists)\n[GPU 1] Skipping batch 20/1122 (already exists)\n[GPU 1] Skipping batch 30/1122 (already exists)\n[GPU 1] Skipping batch 40/1122 (already exists)\n[GPU 1] Skipping batch 50/1122 (already exists)\n[GPU 1] Skipping batch 60/1122 (already exists)\n[GPU 1] Skipping batch 70/1122 (already exists)\n[GPU 1] Skipping batch 80/1122 (already exists)\n[GPU 1] Skipping batch 90/1122 (already exists)\n[GPU 1] Skipping batch 100/1122 (already exists)\n[GPU 1] Skipping batch 110/1122 (already exists)\n[GPU 1] Skipping batch 120/1122 (already exists)\n[GPU 1] Skipping batch 130/1122 (already exists)\n[GPU 1] Skipping batch 140/1122 (already exists)\n[GPU 1] Skipping batch 150/1122 (already exists)\n[GPU 1] Skipping batch 160/1122 (already exists)\n[GPU 1] Skipping batch 170/1122 (already exists)\n[GPU 1] Skipping batch 180/1122 (already exists)\n[GPU 1] Skipping batch 190/1122 (already exists)\n[GPU 1] Skipping batch 200/1122 (already exists)\n[GPU 1] Skipping batch 210/1122 (already exists)\n[GPU 1] Skipping batch 220/1122 (already exists)\n[GPU 1] Skipping batch 230/1122 (already exists)\n[GPU 1] Skipping batch 240/1122 (already exists)\n[GPU 1] Skipping batch 250/1122 (already exists)\n[GPU 1] Skipping batch 260/1122 (already exists)\n[GPU 1] Skipping batch 270/1122 (already exists)\n[GPU 1] Skipping batch 280/1122 (already exists)\n[GPU 1] Skipping batch 290/1122 (already exists)\n[GPU 1] Skipping batch 300/1122 (already exists)\n[GPU 1] Skipping batch 310/1122 (already exists)\n[GPU 1] Skipping batch 320/1122 (already exists)\n[GPU 1] Skipping batch 330/1122 (already exists)\n[GPU 1] Skipping batch 340/1122 (already exists)\n[GPU 1] Skipping batch 350/1122 (already exists)\n[GPU 1] Skipping batch 360/1122 (already exists)\n[GPU 1] Skipping batch 370/1122 (already exists)\n[GPU 1] Skipping batch 380/1122 (already exists)\n[GPU 1] Skipping batch 390/1122 (already exists)\n[GPU 1] Skipping batch 400/1122 (already exists)\n[GPU 1] Skipping batch 410/1122 (already exists)\n[GPU 1] Skipping batch 420/1122 (already exists)\n[GPU 1] Skipping batch 430/1122 (already exists)\n[GPU 1] Skipping batch 440/1122 (already exists)\n[GPU 1] Skipping batch 450/1122 (already exists)\n[GPU 1] Skipping batch 460/1122 (already exists)\n[GPU 1] Skipping batch 470/1122 (already exists)\n[GPU 1] Skipping batch 480/1122 (already exists)\n[GPU 1] Skipping batch 490/1122 (already exists)\n[GPU 1] Skipping batch 500/1122 (already exists)\n[GPU 1] Skipping batch 510/1122 (already exists)\n[GPU 1] Skipping batch 520/1122 (already exists)\n[GPU 1] Skipping batch 530/1122 (already exists)\n[GPU 1] Skipping batch 540/1122 (already exists)\n[GPU 1] Skipping batch 550/1122 (already exists)\n[GPU 1] Skipping batch 560/1122 (already exists)\n[GPU 1] Skipping batch 570/1122 (already exists)\n[GPU 1] Skipping batch 580/1122 (already exists)\n[GPU 1] Skipping batch 590/1122 (already exists)\n[GPU 1] Skipping batch 600/1122 (already exists)\n[GPU 1] Skipping batch 610/1122 (already exists)\n[GPU 1] Skipping batch 620/1122 (already exists)\n[GPU 1] Skipping batch 630/1122 (already exists)\n[GPU 1] Skipping batch 640/1122 (already exists)\n[GPU 1] Skipping batch 650/1122 (already exists)\n[GPU 1] Skipping batch 660/1122 (already exists)\n[GPU 1] Skipping batch 670/1122 (already exists)\n[GPU 1] Skipping batch 680/1122 (already exists)\n[GPU 1] Skipping batch 690/1122 (already exists)\n[GPU 1] Skipping batch 700/1122 (already exists)\n[GPU 1] Skipping batch 710/1122 (already exists)\n[GPU 1] Skipping batch 720/1122 (already exists)\n[GPU 1] Skipping batch 730/1122 (already exists)\n[GPU 1] Skipping batch 740/1122 (already exists)\n[GPU 1] Skipping batch 750/1122 (already exists)\n[GPU 1] Skipping batch 760/1122 (already exists)\n[GPU 1] Skipping batch 770/1122 (already exists)\n[GPU 1] Skipping batch 780/1122 (already exists)\n[GPU 1] Skipping batch 790/1122 (already exists)\n[GPU 1] Skipping batch 800/1122 (already exists)\n[GPU 1] Skipping batch 810/1122 (already exists)\n[GPU 1] Skipping batch 820/1122 (already exists)\n[GPU 1] Skipping batch 830/1122 (already exists)\n[GPU 1] Skipping batch 840/1122 (already exists)\n[GPU 1] Skipping batch 850/1122 (already exists)\n[GPU 1] Skipping batch 860/1122 (already exists)\n[GPU 1] Skipping batch 870/1122 (already exists)\n[GPU 1] Skipping batch 880/1122 (already exists)\n[GPU 1] Skipping batch 890/1122 (already exists)\n[GPU 1] Skipping batch 900/1122 (already exists)\n[GPU 1] Skipping batch 910/1122 (already exists)\n[GPU 1] Skipping batch 920/1122 (already exists)\n[GPU 1] Skipping batch 930/1122 (already exists)\n[GPU 1] Skipping batch 940/1122 (already exists)\n[GPU 1] Skipping batch 950/1122 (already exists)\n[GPU 1] Skipping batch 960/1122 (already exists)\n[GPU 1] Skipping batch 970/1122 (already exists)\n[GPU 1] Skipping batch 980/1122 (already exists)\n[GPU 1] Skipping batch 990/1122 (already exists)\n[GPU 1] Skipping batch 1000/1122 (already exists)\n[GPU 1] Skipping batch 1010/1122 (already exists)\n[GPU 1] Skipping batch 1020/1122 (already exists)\n[GPU 1] Skipping batch 1030/1122 (already exists)\n[GPU 1] Skipping batch 1040/1122 (already exists)\n[GPU 1] Skipping batch 1050/1122 (already exists)\n[GPU 1] Skipping batch 1060/1122 (already exists)\n[GPU 1] Skipping batch 1070/1122 (already exists)\n[GPU 1] Skipping batch 1080/1122 (already exists)\n[GPU 1] Skipping batch 1090/1122 (already exists)\n[GPU 1] Skipping batch 1100/1122 (already exists)\n[GPU 1] Skipping batch 1110/1122 (already exists)\n[GPU 1] Skipping batch 1120/1122 (already exists)\n[GPU 1] Finished.\n[GPU 0] Completed batch 846/1122\n[GPU 0] Completed batch 847/1122\n[GPU 0] Completed batch 848/1122\n[GPU 0] Completed batch 849/1122\n[GPU 0] Completed batch 850/1122\n[GPU 0] Completed batch 851/1122\n[GPU 0] Completed batch 852/1122\n[GPU 0] Completed batch 853/1122\n[GPU 0] Completed batch 854/1122\n[GPU 0] Completed batch 855/1122\n[GPU 0] Completed batch 856/1122\n[GPU 0] Completed batch 857/1122\n[GPU 0] Completed batch 858/1122\n[GPU 0] Completed batch 859/1122\n[GPU 0] Completed batch 860/1122\n[GPU 0] Completed batch 861/1122\n[GPU 0] Completed batch 862/1122\n[GPU 0] Completed batch 863/1122\n[GPU 0] Completed batch 864/1122\n[GPU 0] Completed batch 865/1122\n[GPU 0] Completed batch 866/1122\n[GPU 0] Completed batch 867/1122\n[GPU 0] Completed batch 868/1122\n[GPU 0] Completed batch 869/1122\n[GPU 0] Completed batch 870/1122\n[GPU 0] Completed batch 871/1122\n[GPU 0] Completed batch 872/1122\n[GPU 0] Completed batch 873/1122\n[GPU 0] Completed batch 874/1122\n[GPU 0] Completed batch 875/1122\n[GPU 0] Completed batch 876/1122\n[GPU 0] Completed batch 877/1122\n[GPU 0] Completed batch 878/1122\n[GPU 0] Completed batch 879/1122\n[GPU 0] Completed batch 880/1122\n[GPU 0] Completed batch 881/1122\n[GPU 0] Completed batch 882/1122\n[GPU 0] Completed batch 883/1122\n[GPU 0] Completed batch 884/1122\n[GPU 0] Completed batch 885/1122\n[GPU 0] Completed batch 886/1122\n[GPU 0] Completed batch 887/1122\n[GPU 0] Completed batch 888/1122\n[GPU 0] Completed batch 889/1122\n[GPU 0] Completed batch 890/1122\n[GPU 0] Completed batch 891/1122\n[GPU 0] Completed batch 892/1122\n[GPU 0] Completed batch 893/1122\n[GPU 0] Completed batch 894/1122\n[GPU 0] Completed batch 895/1122\n[GPU 0] Completed batch 896/1122\n[GPU 0] Completed batch 897/1122\n[GPU 0] Completed batch 898/1122\n[GPU 0] Completed batch 899/1122\n[GPU 0] Completed batch 900/1122\n[GPU 0] Completed batch 901/1122\n[GPU 0] Completed batch 902/1122\n[GPU 0] Completed batch 903/1122\n[GPU 0] Completed batch 904/1122\n[GPU 0] Completed batch 905/1122\n[GPU 0] Completed batch 906/1122\n[GPU 0] Completed batch 907/1122\n[GPU 0] Completed batch 908/1122\n[GPU 0] Completed batch 909/1122\n[GPU 0] Completed batch 910/1122\n[GPU 0] Completed batch 911/1122\n[GPU 0] Completed batch 912/1122\n[GPU 0] Completed batch 913/1122\n[GPU 0] Completed batch 914/1122\n[GPU 0] Completed batch 915/1122\n[GPU 0] Completed batch 916/1122\n[GPU 0] Completed batch 917/1122\n[GPU 0] Completed batch 918/1122\n[GPU 0] Completed batch 919/1122\n[GPU 0] Completed batch 920/1122\n[GPU 0] Completed batch 921/1122\n[GPU 0] Completed batch 922/1122\n[GPU 0] Completed batch 923/1122\n[GPU 0] Completed batch 924/1122\n[GPU 0] Completed batch 925/1122\n[GPU 0] Completed batch 926/1122\n[GPU 0] Completed batch 927/1122\n[GPU 0] Completed batch 928/1122\n[GPU 0] Completed batch 929/1122\n[GPU 0] Completed batch 930/1122\n[GPU 0] Completed batch 931/1122\n[GPU 0] Completed batch 932/1122\n[GPU 0] Completed batch 933/1122\n[GPU 0] Completed batch 934/1122\n[GPU 0] Completed batch 935/1122\n[GPU 0] Completed batch 936/1122\n[GPU 0] Completed batch 937/1122\n[GPU 0] Completed batch 938/1122\n[GPU 0] Completed batch 939/1122\n[GPU 0] Completed batch 940/1122\n[GPU 0] Completed batch 941/1122\n[GPU 0] Completed batch 942/1122\n[GPU 0] Completed batch 943/1122\n[GPU 0] Completed batch 944/1122\n[GPU 0] Completed batch 945/1122\n[GPU 0] Completed batch 946/1122\n[GPU 0] Completed batch 947/1122\n[GPU 0] Completed batch 948/1122\n[GPU 0] Completed batch 949/1122\n[GPU 0] Completed batch 950/1122\n[GPU 0] Completed batch 951/1122\n[GPU 0] Completed batch 952/1122\n[GPU 0] Completed batch 953/1122\n[GPU 0] Completed batch 954/1122\n[GPU 0] Completed batch 955/1122\n[GPU 0] Completed batch 956/1122\n[GPU 0] Completed batch 957/1122\n[GPU 0] Completed batch 958/1122\n[GPU 0] Completed batch 959/1122\n[GPU 0] Completed batch 960/1122\n[GPU 0] Completed batch 961/1122\n[GPU 0] Completed batch 962/1122\n[GPU 0] Completed batch 963/1122\n[GPU 0] Completed batch 964/1122\n[GPU 0] Completed batch 965/1122\n[GPU 0] Completed batch 966/1122\n[GPU 0] Completed batch 967/1122\n[GPU 0] Completed batch 968/1122\n[GPU 0] Completed batch 969/1122\n[GPU 0] Completed batch 970/1122\n[GPU 0] Completed batch 971/1122\n[GPU 0] Completed batch 972/1122\n[GPU 0] Completed batch 973/1122\n[GPU 0] Completed batch 974/1122\n[GPU 0] Completed batch 975/1122\n[GPU 0] Completed batch 976/1122\n[GPU 0] Completed batch 977/1122\n[GPU 0] Completed batch 978/1122\n[GPU 0] Completed batch 979/1122\n[GPU 0] Completed batch 980/1122\n[GPU 0] Completed batch 981/1122\n[GPU 0] Completed batch 982/1122\n[GPU 0] Completed batch 983/1122\n[GPU 0] Completed batch 984/1122\n[GPU 0] Completed batch 985/1122\n[GPU 0] Completed batch 986/1122\n[GPU 0] Completed batch 987/1122\n[GPU 0] Completed batch 988/1122\n[GPU 0] Completed batch 989/1122\n[GPU 0] Completed batch 990/1122\n[GPU 0] Completed batch 991/1122\n[GPU 0] Completed batch 992/1122\n[GPU 0] Completed batch 993/1122\n[GPU 0] Completed batch 994/1122\n[GPU 0] Completed batch 995/1122\n[GPU 0] Completed batch 996/1122\n[GPU 0] Completed batch 997/1122\n[GPU 0] Completed batch 998/1122\n[GPU 0] Completed batch 999/1122\n[GPU 0] Completed batch 1000/1122\n[GPU 0] Completed batch 1001/1122\n[GPU 0] Completed batch 1002/1122\n[GPU 0] Completed batch 1003/1122\n[GPU 0] Completed batch 1004/1122\n[GPU 0] Completed batch 1005/1122\n[GPU 0] Completed batch 1006/1122\n[GPU 0] Completed batch 1007/1122\n[GPU 0] Completed batch 1008/1122\n[GPU 0] Completed batch 1009/1122\n[GPU 0] Completed batch 1010/1122\n[GPU 0] Completed batch 1011/1122\n[GPU 0] Completed batch 1012/1122\n[GPU 0] Completed batch 1013/1122\n[GPU 0] Completed batch 1014/1122\n[GPU 0] Completed batch 1015/1122\n[GPU 0] Completed batch 1016/1122\n[GPU 0] Completed batch 1017/1122\n[GPU 0] Completed batch 1018/1122\n[GPU 0] Completed batch 1019/1122\n[GPU 0] Completed batch 1020/1122\n[GPU 0] Completed batch 1021/1122\n[GPU 0] Completed batch 1022/1122\n[GPU 0] Completed batch 1023/1122\n[GPU 0] Completed batch 1024/1122\n[GPU 0] Completed batch 1025/1122\n[GPU 0] Completed batch 1026/1122\n[GPU 0] Completed batch 1027/1122\n[GPU 0] Completed batch 1028/1122\n[GPU 0] Completed batch 1029/1122\n[GPU 0] Completed batch 1030/1122\n[GPU 0] Completed batch 1031/1122\n[GPU 0] Completed batch 1032/1122\n[GPU 0] Completed batch 1033/1122\n[GPU 0] Completed batch 1034/1122\n[GPU 0] Completed batch 1035/1122\n[GPU 0] Completed batch 1036/1122\n[GPU 0] Completed batch 1037/1122\n[GPU 0] Completed batch 1038/1122\n[GPU 0] Completed batch 1039/1122\n[GPU 0] Completed batch 1040/1122\n[GPU 0] Completed batch 1041/1122\n[GPU 0] Completed batch 1042/1122\n[GPU 0] Completed batch 1043/1122\n[GPU 0] Completed batch 1044/1122\n[GPU 0] Completed batch 1045/1122\n[GPU 0] Completed batch 1046/1122\n[GPU 0] Completed batch 1047/1122\n[GPU 0] Completed batch 1048/1122\n[GPU 0] Completed batch 1049/1122\n[GPU 0] Completed batch 1050/1122\n[GPU 0] Completed batch 1051/1122\n[GPU 0] Completed batch 1052/1122\n[GPU 0] Completed batch 1053/1122\n[GPU 0] Completed batch 1054/1122\n[GPU 0] Completed batch 1055/1122\n[GPU 0] Completed batch 1056/1122\n[GPU 0] Completed batch 1057/1122\n[GPU 0] Completed batch 1058/1122\n[GPU 0] Completed batch 1059/1122\n[GPU 0] Completed batch 1060/1122\n[GPU 0] Completed batch 1061/1122\n[GPU 0] Completed batch 1062/1122\n[GPU 0] Completed batch 1063/1122\n[GPU 0] Completed batch 1064/1122\n[GPU 0] Completed batch 1065/1122\n[GPU 0] Completed batch 1066/1122\n[GPU 0] Completed batch 1067/1122\n[GPU 0] Completed batch 1068/1122\n[GPU 0] Completed batch 1069/1122\n[GPU 0] Completed batch 1070/1122\n[GPU 0] Completed batch 1071/1122\n[GPU 0] Completed batch 1072/1122\n[GPU 0] Completed batch 1073/1122\n[GPU 0] Completed batch 1074/1122\n[GPU 0] Completed batch 1075/1122\n[GPU 0] Completed batch 1076/1122\n[GPU 0] Completed batch 1077/1122\n[GPU 0] Completed batch 1078/1122\n[GPU 0] Completed batch 1079/1122\n[GPU 0] Completed batch 1080/1122\n[GPU 0] Completed batch 1081/1122\n[GPU 0] Completed batch 1082/1122\n[GPU 0] Completed batch 1083/1122\n[GPU 0] Completed batch 1084/1122\n[GPU 0] Completed batch 1085/1122\n[GPU 0] Completed batch 1086/1122\n[GPU 0] Completed batch 1087/1122\n[GPU 0] Completed batch 1088/1122\n[GPU 0] Completed batch 1089/1122\n[GPU 0] Completed batch 1090/1122\n[GPU 0] Completed batch 1091/1122\n[GPU 0] Completed batch 1092/1122\n[GPU 0] Completed batch 1093/1122\n[GPU 0] Completed batch 1094/1122\n[GPU 0] Completed batch 1095/1122\n[GPU 0] Completed batch 1096/1122\n[GPU 0] Completed batch 1097/1122\n[GPU 0] Completed batch 1098/1122\n[GPU 0] Completed batch 1099/1122\n[GPU 0] Completed batch 1100/1122\n[GPU 0] Completed batch 1101/1122\n[GPU 0] Completed batch 1102/1122\n[GPU 0] Completed batch 1103/1122\n[GPU 0] Completed batch 1104/1122\n[GPU 0] Completed batch 1105/1122\n[GPU 0] Completed batch 1106/1122\n[GPU 0] Completed batch 1107/1122\n[GPU 0] Completed batch 1108/1122\n[GPU 0] Completed batch 1109/1122\n[GPU 0] Completed batch 1110/1122\n[GPU 0] Completed batch 1111/1122\n[GPU 0] Completed batch 1112/1122\n[GPU 0] Completed batch 1113/1122\n[GPU 0] Completed batch 1114/1122\n[GPU 0] Completed batch 1115/1122\n[GPU 0] Completed batch 1116/1122\n[GPU 0] Completed batch 1117/1122\n[GPU 0] Completed batch 1118/1122\n[GPU 0] Completed batch 1119/1122\n[GPU 0] Completed batch 1120/1122\n[GPU 0] Completed batch 1121/1122\n[GPU 0] Finished.\nSubmission saved to submission.tsv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Merging","metadata":{}},{"cell_type":"code","source":"import os\nimport zipfile\nfrom tqdm import tqdm\n\n# --- Configuration ---\nTEMP_DIR = \"temp_inference_batches\"\nOUTPUT_ZIP = \"submission.zip\"\nINTERNAL_FILENAME = \"submission.tsv\"\n\ndef merge_compress_cleanup():\n    # 1. Check if temp dir exists\n    if not os.path.exists(TEMP_DIR):\n        print(f\"Error: {TEMP_DIR} not found. Did the inference run?\")\n        return\n\n    # 2. Get list of files\n    batch_files = sorted([f for f in os.listdir(TEMP_DIR) if f.startswith(\"batch_\")])\n    print(f\"Found {len(batch_files)} batch files to merge.\")\n    \n    if len(batch_files) == 0:\n        print(\"❌ No batch files found! They were likely deleted during the failed merge.\")\n        print(\"   Please RE-RUN the inference step (Step 2).\")\n        print(\"   It will regenerate the missing batches.\")\n        return\n\n    # 3. Clean up previous corrupted zip if exists\n    if os.path.exists(OUTPUT_ZIP):\n        print(f\"Removing existing {OUTPUT_ZIP}...\")\n        os.remove(OUTPUT_ZIP)\n\n    print(f\"Streaming data directly to {OUTPUT_ZIP} and deleting sources...\")\n    \n    # 4. Stream-Zip-Delete Loop\n    with zipfile.ZipFile(OUTPUT_ZIP, 'w', compression=zipfile.ZIP_DEFLATED, allowZip64=True) as zf:\n        \n        # FIX: force_zip64=True is required for files >4GB written via stream\n        with zf.open(INTERNAL_FILENAME, 'w', force_zip64=True) as dest:\n            \n            for fname in tqdm(batch_files):\n                fpath = os.path.join(TEMP_DIR, fname)\n                \n                try:\n                    with open(fpath, 'rb') as src:\n                        while True:\n                            chunk = src.read(1024 * 1024) # 1MB chunks\n                            if not chunk:\n                                break\n                            dest.write(chunk)\n                    \n                    # Delete file immediately to free disk space\n                    os.remove(fpath)\n                    \n                except Exception as e:\n                    print(f\"Error processing {fname}: {e}\")\n                    raise e\n\n    print(\"\\n----------------------------------------------\")\n    print(\"Merge Complete!\")\n    print(f\"1. Raw batch files deleted.\")\n    print(f\"2. Submission saved to: {OUTPUT_ZIP}\")\n    print(f\"3. File size: {os.path.getsize(OUTPUT_ZIP) / (1024*1024):.2f} MB\")\n    print(\"----------------------------------------------\")\n\n# Run it\nmerge_compress_cleanup()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T09:55:56.304750Z","iopub.execute_input":"2026-01-28T09:55:56.305186Z","iopub.status.idle":"2026-01-28T10:07:45.729248Z","shell.execute_reply.started":"2026-01-28T09:55:56.305150Z","shell.execute_reply":"2026-01-28T10:07:45.728655Z"}},"outputs":[{"name":"stdout","text":"Found 2244 batch files to merge.\nStreaming data directly to submission.zip and deleting sources...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2244/2244 [11:49<00:00,  3.16it/s]","output_type":"stream"},{"name":"stdout","text":"\n----------------------------------------------\nMerge Complete!\n1. Raw batch files deleted.\n2. Submission saved to: submission.zip\n3. File size: 3275.72 MB\n----------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink('submission.zip')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T10:12:14.640001Z","iopub.execute_input":"2026-01-28T10:12:14.640507Z","iopub.status.idle":"2026-01-28T10:12:14.645666Z","shell.execute_reply.started":"2026-01-28T10:12:14.640478Z","shell.execute_reply":"2026-01-28T10:12:14.645128Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/submission.zip","text/html":"<a href='submission.zip' target='_blank'>submission.zip</a><br>"},"metadata":{}}],"execution_count":5}]}